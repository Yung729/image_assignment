{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b35316f-bd4a-44df-8c77-da44cb7385cd",
   "metadata": {},
   "source": [
    "Train PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33c9fcc5-9562-4d04-898f-c4c319dc8f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 person directories: ['S001', 'S002', 'S003', 'S004', 'S005', 'S006']\n",
      "\n",
      "=== Training model for S001 ===\n",
      "Face images found for S001: 30\n",
      "Setting n_components to: 30\n",
      "Loading face data from student_faces\\S001\\S001_faces_detection.json\n",
      "Found 30 faces in JSON\n",
      "Successfully loaded 30 face images\n",
      "Loaded 30 face images for S001\n",
      "\n",
      "Training PCA model with 30 faces...\n",
      "Original feature dimension: 4096\n",
      "Reducing to 30 components\n",
      "Mean face calculated with shape: (4096,)\n",
      "Generated 30 eigenfaces\n",
      "PCA explained variance ratio: 1.000\n",
      "Reduced feature dimension: 30\n",
      "Mean face saved to: student_faces\\S001\\multi_person_mean_face.jpg\n",
      "Saved 10 eigenfaces to student_faces\\S001\n",
      "Model information saved to: student_faces\\S001\\multi_person_model_info.json\n",
      "Model saved to student_faces\\S001\\face_model.pkl\n",
      "Training completed successfully for S001!\n",
      "Model saved to: student_faces\\S001\\face_model.pkl\n",
      "Eigenfaces and mean face saved to: student_faces\\S001\n",
      "\n",
      "=== Training model for S002 ===\n",
      "Face images found for S002: 30\n",
      "Setting n_components to: 30\n",
      "Loading face data from student_faces\\S002\\S002_faces_detection.json\n",
      "Found 30 faces in JSON\n",
      "Successfully loaded 30 face images\n",
      "Loaded 30 face images for S002\n",
      "\n",
      "Training PCA model with 30 faces...\n",
      "Original feature dimension: 4096\n",
      "Reducing to 30 components\n",
      "Mean face calculated with shape: (4096,)\n",
      "Generated 30 eigenfaces\n",
      "PCA explained variance ratio: 1.000\n",
      "Reduced feature dimension: 30\n",
      "Mean face saved to: student_faces\\S002\\multi_person_mean_face.jpg\n",
      "Saved 10 eigenfaces to student_faces\\S002\n",
      "Model information saved to: student_faces\\S002\\multi_person_model_info.json\n",
      "Model saved to student_faces\\S002\\face_model.pkl\n",
      "Training completed successfully for S002!\n",
      "Model saved to: student_faces\\S002\\face_model.pkl\n",
      "Eigenfaces and mean face saved to: student_faces\\S002\n",
      "\n",
      "=== Training model for S003 ===\n",
      "Face images found for S003: 30\n",
      "Setting n_components to: 30\n",
      "Loading face data from student_faces\\S003\\S003_faces_detection.json\n",
      "Found 30 faces in JSON\n",
      "Successfully loaded 30 face images\n",
      "Loaded 30 face images for S003\n",
      "\n",
      "Training PCA model with 30 faces...\n",
      "Original feature dimension: 4096\n",
      "Reducing to 30 components\n",
      "Mean face calculated with shape: (4096,)\n",
      "Generated 30 eigenfaces\n",
      "PCA explained variance ratio: 1.000\n",
      "Reduced feature dimension: 30\n",
      "Mean face saved to: student_faces\\S003\\multi_person_mean_face.jpg\n",
      "Saved 10 eigenfaces to student_faces\\S003\n",
      "Model information saved to: student_faces\\S003\\multi_person_model_info.json\n",
      "Model saved to student_faces\\S003\\face_model.pkl\n",
      "Training completed successfully for S003!\n",
      "Model saved to: student_faces\\S003\\face_model.pkl\n",
      "Eigenfaces and mean face saved to: student_faces\\S003\n",
      "\n",
      "=== Training model for S004 ===\n",
      "Face images found for S004: 30\n",
      "Setting n_components to: 30\n",
      "Loading face data from student_faces\\S004\\S004_faces_detection.json\n",
      "Found 30 faces in JSON\n",
      "Successfully loaded 30 face images\n",
      "Loaded 30 face images for S004\n",
      "\n",
      "Training PCA model with 30 faces...\n",
      "Original feature dimension: 4096\n",
      "Reducing to 30 components\n",
      "Mean face calculated with shape: (4096,)\n",
      "Generated 30 eigenfaces\n",
      "PCA explained variance ratio: 1.000\n",
      "Reduced feature dimension: 30\n",
      "Mean face saved to: student_faces\\S004\\multi_person_mean_face.jpg\n",
      "Saved 10 eigenfaces to student_faces\\S004\n",
      "Model information saved to: student_faces\\S004\\multi_person_model_info.json\n",
      "Model saved to student_faces\\S004\\face_model.pkl\n",
      "Training completed successfully for S004!\n",
      "Model saved to: student_faces\\S004\\face_model.pkl\n",
      "Eigenfaces and mean face saved to: student_faces\\S004\n",
      "\n",
      "=== Training model for S005 ===\n",
      "Face images found for S005: 30\n",
      "Setting n_components to: 30\n",
      "Loading face data from student_faces\\S005\\S005_faces_detection.json\n",
      "Found 30 faces in JSON\n",
      "Successfully loaded 30 face images\n",
      "Loaded 30 face images for S005\n",
      "\n",
      "Training PCA model with 30 faces...\n",
      "Original feature dimension: 4096\n",
      "Reducing to 30 components\n",
      "Mean face calculated with shape: (4096,)\n",
      "Generated 30 eigenfaces\n",
      "PCA explained variance ratio: 1.000\n",
      "Reduced feature dimension: 30\n",
      "Mean face saved to: student_faces\\S005\\multi_person_mean_face.jpg\n",
      "Saved 10 eigenfaces to student_faces\\S005\n",
      "Model information saved to: student_faces\\S005\\multi_person_model_info.json\n",
      "Model saved to student_faces\\S005\\face_model.pkl\n",
      "Training completed successfully for S005!\n",
      "Model saved to: student_faces\\S005\\face_model.pkl\n",
      "Eigenfaces and mean face saved to: student_faces\\S005\n",
      "\n",
      "=== Training model for S006 ===\n",
      "Generating detection JSON for S006...\n",
      "Found 30 face images for S006\n",
      "Generated student_faces\\S006\\S006_faces_detection.json\n",
      "Total faces: 30\n",
      "Face images found for S006: 30\n",
      "Setting n_components to: 30\n",
      "Loading face data from student_faces\\S006\\S006_faces_detection.json\n",
      "Found 30 faces in JSON\n",
      "Successfully loaded 30 face images\n",
      "Loaded 30 face images for S006\n",
      "\n",
      "Training PCA model with 30 faces...\n",
      "Original feature dimension: 4096\n",
      "Reducing to 30 components\n",
      "Mean face calculated with shape: (4096,)\n",
      "Generated 30 eigenfaces\n",
      "PCA explained variance ratio: 1.000\n",
      "Reduced feature dimension: 30\n",
      "Mean face saved to: student_faces\\S006\\multi_person_mean_face.jpg\n",
      "Saved 10 eigenfaces to student_faces\\S006\n",
      "Model information saved to: student_faces\\S006\\multi_person_model_info.json\n",
      "Model saved to student_faces\\S006\\face_model.pkl\n",
      "Training completed successfully for S006!\n",
      "Model saved to: student_faces\\S006\\face_model.pkl\n",
      "Eigenfaces and mean face saved to: student_faces\\S006\n",
      "\n",
      "=== Training Summary ===\n",
      "Total persons processed: 6\n",
      "Successful trainings: 6\n",
      "Failed trainings: 0\n",
      "\n",
      "Models saved in individual person directories under student_faces\n",
      "Each model can be used with scan-template scripts for person-specific recognition\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import glob\n",
    "import re\n",
    "import subprocess\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "class MultiFaceTrainer:\n",
    "    def __init__(self, n_components=50):\n",
    "        \"\"\"\n",
    "        Initialize multi-person face trainer with eigenfaces support\n",
    "\n",
    "        Args:\n",
    "            n_components: Number of features after PCA dimensionality reduction\n",
    "        \"\"\"\n",
    "        self.n_components = n_components\n",
    "        self.pca = PCA(n_components=n_components)\n",
    "        self.scaler = StandardScaler()\n",
    "        self.face_features = []\n",
    "        self.face_labels = []\n",
    "        self.face_info = []\n",
    "        self.is_trained = False\n",
    "        self.mean_face = None\n",
    "        self.eigenfaces = None\n",
    "        self.face_shape = (64, 64)  # Standard face image size\n",
    "        self.person_id_map = {}\n",
    "\n",
    "    def generate_detection_json_for_person(self, person_name, face_dir):\n",
    "        \"\"\"\n",
    "        Generate detection JSON file for a person based on existing face images\n",
    "\n",
    "        Args:\n",
    "            person_name: Name of the person\n",
    "            face_dir: Directory containing face images\n",
    "        \"\"\"\n",
    "        print(f\"Generating detection JSON for {person_name}...\")\n",
    "\n",
    "        # Find all face images in the directory\n",
    "        face_images = []\n",
    "\n",
    "        # Look for different naming patterns\n",
    "        patterns = [\n",
    "            f\"{person_name}_face_*.jpg\",\n",
    "            \"face_*_frame_*.jpg\",\n",
    "            \"*.jpg\"\n",
    "        ]\n",
    "\n",
    "        for pattern in patterns:\n",
    "            search_path = os.path.join(face_dir, pattern)\n",
    "            found_files = glob.glob(search_path)\n",
    "            for file_path in found_files:\n",
    "                filename = os.path.basename(file_path)\n",
    "                # Skip non-face images (like eigenfaces, mean_face, etc.)\n",
    "                if any(skip in filename.lower() for skip in ['eigenface', 'mean_face', 'model_info']):\n",
    "                    continue\n",
    "                face_images.append(file_path)\n",
    "\n",
    "        # Remove duplicates and sort\n",
    "        face_images = sorted(list(set(face_images)))\n",
    "\n",
    "        print(f\"Found {len(face_images)} face images for {person_name}\")\n",
    "\n",
    "        if len(face_images) == 0:\n",
    "            print(f\"No face images found for {person_name}\")\n",
    "            return None\n",
    "\n",
    "        # Generate face data\n",
    "        all_face_data = []\n",
    "\n",
    "        for face_id, image_path in enumerate(face_images):\n",
    "            filename = os.path.basename(image_path)\n",
    "\n",
    "            # Try to extract frame number from filename\n",
    "            frame_number = 0\n",
    "\n",
    "            # Pattern 1: face_XXXXXX_frame_XXXXXX.jpg\n",
    "            match = re.search(r'face_\\d+_frame_(\\d+)', filename)\n",
    "            if match:\n",
    "                frame_number = int(match.group(1))\n",
    "\n",
    "            # Pattern 2: person_face_XXXX.jpg\n",
    "            elif re.search(r'_face_(\\d+)', filename):\n",
    "                match = re.search(r'_face_(\\d+)', filename)\n",
    "                frame_number = int(match.group(1))\n",
    "\n",
    "            # Try to get image dimensions\n",
    "            try:\n",
    "                img = cv2.imread(image_path)\n",
    "                if img is not None:\n",
    "                    height, width = img.shape[:2]\n",
    "                else:\n",
    "                    width, height = 64, 64  # Default size\n",
    "            except:\n",
    "                width, height = 64, 64  # Default size\n",
    "\n",
    "            # Calculate timestamp (assume 30 FPS)\n",
    "            fps = 30.0\n",
    "            timestamp = frame_number / fps\n",
    "\n",
    "            # Create face data entry\n",
    "            face_data = {\n",
    "                \"face_id\": face_id,\n",
    "                \"frame_number\": frame_number,\n",
    "                \"timestamp\": timestamp,\n",
    "                \"x\": 0,  # Unknown, set to 0\n",
    "                \"y\": 0,  # Unknown, set to 0\n",
    "                \"width\": width,\n",
    "                \"height\": height,\n",
    "                \"center_x\": width // 2,\n",
    "                \"center_y\": height // 2,\n",
    "                \"area\": width * height,\n",
    "                \"image_path\": image_path,\n",
    "                \"image_filename\": filename\n",
    "            }\n",
    "\n",
    "            all_face_data.append(face_data)\n",
    "\n",
    "        # Create info structure\n",
    "        info = {\n",
    "            \"total_frames\": max([face['frame_number'] for face in all_face_data]) + 1 if all_face_data else 0,\n",
    "            \"fps\": fps,\n",
    "            \"total_faces_detected\": len(all_face_data),\n",
    "            \"processing_date\": datetime.now().isoformat(),\n",
    "            \"faces\": all_face_data\n",
    "        }\n",
    "\n",
    "        # Save JSON file\n",
    "        json_path = os.path.join(face_dir, f\"{person_name}_faces_detection.json\")\n",
    "\n",
    "        with open(json_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(info, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "        print(f\"Generated {json_path}\")\n",
    "        print(f\"Total faces: {len(all_face_data)}\")\n",
    "\n",
    "        return json_path\n",
    "\n",
    "    def count_face_images_in_directory(self, directory):\n",
    "        \"\"\"\n",
    "        Count total number of face images in a directory\n",
    "\n",
    "        Args:\n",
    "            directory: Directory containing face images (can be base dir or person dir)\n",
    "\n",
    "        Returns:\n",
    "            Total number of face images\n",
    "        \"\"\"\n",
    "        if not os.path.exists(directory):\n",
    "            return 0\n",
    "\n",
    "        # Check if this directory contains subdirectories (base directory case)\n",
    "        subdirs = [d for d in os.listdir(directory)\n",
    "                   if os.path.isdir(os.path.join(directory, d))]\n",
    "\n",
    "        # If there are subdirectories, this is a base directory\n",
    "        if subdirs and any(os.path.exists(os.path.join(directory, d, f\"{d}_faces_detection.json\")) or\n",
    "                           glob.glob(os.path.join(directory, d, \"*.jpg\")) for d in subdirs):\n",
    "            total_images = 0\n",
    "            for person_name in subdirs:\n",
    "                person_dir = os.path.join(directory, person_name)\n",
    "                person_count = self._count_face_images_in_single_dir(person_dir)\n",
    "                total_images += person_count\n",
    "                print(f\"{person_name}: {person_count} face images\")\n",
    "            return total_images\n",
    "        else:\n",
    "            # This is a single person directory\n",
    "            return self._count_face_images_in_single_dir(directory)\n",
    "\n",
    "    def _count_face_images_in_single_dir(self, person_dir):\n",
    "        \"\"\"\n",
    "        Count face images in a single person directory\n",
    "\n",
    "        Args:\n",
    "            person_dir: Person's directory\n",
    "        \"\"\"\n",
    "        if not os.path.exists(person_dir):\n",
    "            return 0\n",
    "\n",
    "        # Count JPG files, excluding eigenfaces and mean_face\n",
    "        jpg_files = glob.glob(os.path.join(person_dir, \"*.jpg\"))\n",
    "        face_images = [f for f in jpg_files\n",
    "                       if not any(skip in os.path.basename(f).lower()\n",
    "                                  for skip in ['eigenface', 'mean_face', 'model_info'])]\n",
    "\n",
    "        return len(face_images)\n",
    "\n",
    "    def load_all_face_images(self, base_dir):\n",
    "        \"\"\"\n",
    "        Load face data from all person directories\n",
    "\n",
    "        Args:\n",
    "            base_dir: Base directory containing person folders\n",
    "        \"\"\"\n",
    "        print(f\"Loading face data from all persons in {base_dir}\")\n",
    "\n",
    "        if not os.path.exists(base_dir):\n",
    "            print(f\"Error: Directory {base_dir} not found!\")\n",
    "            return 0\n",
    "\n",
    "        # Get all person directories\n",
    "        person_dirs = [d for d in os.listdir(base_dir)\n",
    "                       if os.path.isdir(os.path.join(base_dir, d))]\n",
    "\n",
    "        print(f\"Found {len(person_dirs)} person directories: {person_dirs}\")\n",
    "\n",
    "        all_face_images = []\n",
    "        all_face_info = []\n",
    "        person_id = 0\n",
    "\n",
    "        for person_name in person_dirs:\n",
    "            person_dir = os.path.join(base_dir, person_name)\n",
    "            json_path = os.path.join(person_dir, f\"{person_name}_faces_detection.json\")\n",
    "\n",
    "            # Generate JSON file if it doesn't exist\n",
    "            if not os.path.exists(json_path):\n",
    "                print(f\"JSON file not found for {person_name}, generating...\")\n",
    "                self.generate_detection_json_for_person(person_name, person_dir)\n",
    "\n",
    "            # Load JSON data\n",
    "            if not os.path.exists(json_path):\n",
    "                print(f\"Warning: Could not generate JSON for {person_name}, skipping...\")\n",
    "                continue\n",
    "\n",
    "            with open(json_path, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            faces_data = data['faces']\n",
    "            print(f\"Found {len(faces_data)} faces for {person_name}\")\n",
    "\n",
    "            # Add person to ID mapping\n",
    "            self.person_id_map[person_name] = person_id\n",
    "\n",
    "            for i, face_info in enumerate(faces_data):\n",
    "                image_path = face_info['image_path']\n",
    "\n",
    "                # Check if image file exists\n",
    "                if not os.path.exists(image_path):\n",
    "                    print(f\"Warning: Image {image_path} not found, skipping...\")\n",
    "                    continue\n",
    "\n",
    "                # Read and preprocess image\n",
    "                img = cv2.imread(image_path)\n",
    "                if img is None:\n",
    "                    print(f\"Warning: Could not read image {image_path}, skipping...\")\n",
    "                    continue\n",
    "\n",
    "                # Convert to grayscale and resize\n",
    "                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                resized = cv2.resize(gray, self.face_shape)  # Uniform size\n",
    "\n",
    "                all_face_images.append(resized.flatten())  # Flatten to 1D vector\n",
    "\n",
    "                # Update face info with person information\n",
    "                face_info['person_name'] = person_name\n",
    "                face_info['person_id'] = person_id\n",
    "                all_face_info.append(face_info)\n",
    "\n",
    "            person_id += 1\n",
    "\n",
    "        print(f\"Successfully loaded {len(all_face_images)} face images from {len(self.person_id_map)} persons\")\n",
    "\n",
    "        self.face_images = np.array(all_face_images)\n",
    "        self.face_info = all_face_info\n",
    "\n",
    "        # Create labels array\n",
    "        self.face_labels = np.array([info['person_id'] for info in all_face_info])\n",
    "\n",
    "        return len(all_face_images)\n",
    "\n",
    "    def load_face_images_from_json(self, json_path, person_dir):\n",
    "        \"\"\"\n",
    "        Load face images for a single person from JSON file\n",
    "\n",
    "        Args:\n",
    "            json_path: JSON file path\n",
    "            person_dir: Person's directory containing face images\n",
    "        \"\"\"\n",
    "        print(f\"Loading face data from {json_path}\")\n",
    "\n",
    "        if not os.path.exists(json_path):\n",
    "            print(f\"Error: JSON file {json_path} not found!\")\n",
    "            return 0\n",
    "\n",
    "        # Read JSON data\n",
    "        with open(json_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        faces_data = data['faces']\n",
    "        print(f\"Found {len(faces_data)} faces in JSON\")\n",
    "\n",
    "        face_images = []\n",
    "        valid_faces = []\n",
    "\n",
    "        for i, face_info in enumerate(faces_data):\n",
    "            # Try different ways to construct image path\n",
    "            image_path = None\n",
    "\n",
    "            # Method 1: Use image_filename if available\n",
    "            if 'image_filename' in face_info:\n",
    "                image_path = os.path.join(person_dir, face_info['image_filename'])\n",
    "            # Method 2: Use image_path directly\n",
    "            elif 'image_path' in face_info:\n",
    "                image_path = face_info['image_path']\n",
    "            # Method 3: Fallback - construct from face_id and frame_number\n",
    "            else:\n",
    "                face_id = face_info.get('face_id', i)\n",
    "                frame_number = face_info.get('frame_number', i)\n",
    "                filename = f\"face_{face_id}_frame_{frame_number}.jpg\"\n",
    "                image_path = os.path.join(person_dir, filename)\n",
    "\n",
    "            # Check if image file exists\n",
    "            if not os.path.exists(image_path):\n",
    "                print(f\"Warning: Image {image_path} not found, skipping...\")\n",
    "                continue\n",
    "\n",
    "            # Read and preprocess image\n",
    "            img = cv2.imread(image_path)\n",
    "            if img is None:\n",
    "                print(f\"Warning: Could not read image {image_path}, skipping...\")\n",
    "                continue\n",
    "\n",
    "            # Convert to grayscale and resize\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            resized = cv2.resize(gray, self.face_shape)  # Uniform size\n",
    "\n",
    "            face_images.append(resized.flatten())  # Flatten to 1D vector\n",
    "            valid_faces.append(face_info)\n",
    "\n",
    "        print(f\"Successfully loaded {len(face_images)} face images\")\n",
    "\n",
    "        self.face_images = np.array(face_images)\n",
    "        self.face_info = valid_faces\n",
    "\n",
    "        # Create labels array (all faces belong to the same person, so label = 0)\n",
    "        self.face_labels = np.zeros(len(face_images), dtype=int)\n",
    "\n",
    "        # Set person ID mapping for single person\n",
    "        person_name = os.path.basename(person_dir)\n",
    "        self.person_id_map = {person_name: 0}\n",
    "\n",
    "        return len(face_images)\n",
    "\n",
    "    def train_pca_model(self):\n",
    "        \"\"\"\n",
    "        Train face feature model using PCA and generate eigenfaces\n",
    "        \"\"\"\n",
    "        if len(self.face_images) == 0:\n",
    "            print(\"Error: No face images loaded!\")\n",
    "            return False\n",
    "\n",
    "        if len(self.face_labels) == 0:\n",
    "            print(\"Error: No face labels assigned!\")\n",
    "            return False\n",
    "\n",
    "        print(f\"\\nTraining PCA model with {len(self.face_images)} faces...\")\n",
    "        print(f\"Original feature dimension: {self.face_images.shape[1]}\")\n",
    "        print(f\"Reducing to {self.n_components} components\")\n",
    "\n",
    "        # Calculate mean face\n",
    "        self.mean_face = np.mean(self.face_images, axis=0)\n",
    "        print(f\"Mean face calculated with shape: {self.mean_face.shape}\")\n",
    "\n",
    "        # Standardize features\n",
    "        scaled_features = self.scaler.fit_transform(self.face_images)\n",
    "\n",
    "        # PCA dimensionality reduction\n",
    "        pca_features = self.pca.fit_transform(scaled_features)\n",
    "\n",
    "        # Extract eigenfaces (principal components)\n",
    "        self.eigenfaces = self.pca.components_\n",
    "        print(f\"Generated {len(self.eigenfaces)} eigenfaces\")\n",
    "\n",
    "        print(f\"PCA explained variance ratio: {self.pca.explained_variance_ratio_.sum():.3f}\")\n",
    "        print(f\"Reduced feature dimension: {pca_features.shape[1]}\")\n",
    "\n",
    "        self.face_features = pca_features\n",
    "        self.is_trained = True\n",
    "\n",
    "        return True\n",
    "\n",
    "    def save_eigenfaces(self, output_dir):\n",
    "        \"\"\"\n",
    "        Save eigenfaces and mean face as images\n",
    "\n",
    "        Args:\n",
    "            output_dir: Output directory for saving images\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            print(\"Error: Model not trained yet!\")\n",
    "            return False\n",
    "\n",
    "        # Create output directory if it doesn't exist\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        # Save mean face\n",
    "        mean_face_img = self.mean_face.reshape(self.face_shape)\n",
    "        mean_face_normalized = cv2.normalize(mean_face_img, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "        mean_face_path = os.path.join(output_dir, \"multi_person_mean_face.jpg\")\n",
    "        cv2.imwrite(mean_face_path, mean_face_normalized)\n",
    "        print(f\"Mean face saved to: {mean_face_path}\")\n",
    "\n",
    "        # Save top eigenfaces\n",
    "        num_eigenfaces_to_save = min(10, len(self.eigenfaces))\n",
    "        for i in range(num_eigenfaces_to_save):\n",
    "            eigenface = self.eigenfaces[i].reshape(self.face_shape)\n",
    "            # Normalize eigenface for visualization\n",
    "            eigenface_normalized = cv2.normalize(eigenface, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "            eigenface_path = os.path.join(output_dir, f\"multi_person_eigenface_{i + 1:02d}.jpg\")\n",
    "            cv2.imwrite(eigenface_path, eigenface_normalized)\n",
    "\n",
    "        print(f\"Saved {num_eigenfaces_to_save} eigenfaces to {output_dir}\")\n",
    "\n",
    "        # Save model information\n",
    "        model_info = {\n",
    "            'training_date': datetime.now().isoformat(),\n",
    "            'total_faces': len(self.face_images),\n",
    "            'total_persons': len(self.person_id_map),\n",
    "            'person_id_map': self.person_id_map,\n",
    "            'n_components': self.n_components,\n",
    "            'explained_variance_ratio': float(self.pca.explained_variance_ratio_.sum()),\n",
    "            'face_shape': self.face_shape,\n",
    "            'eigenfaces_saved': num_eigenfaces_to_save\n",
    "        }\n",
    "\n",
    "        info_path = os.path.join(output_dir, \"multi_person_model_info.json\")\n",
    "        with open(info_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(model_info, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "        print(f\"Model information saved to: {info_path}\")\n",
    "        return True\n",
    "\n",
    "    def save_model(self, model_path):\n",
    "        \"\"\"\n",
    "        Save trained model with eigenfaces support\n",
    "\n",
    "        Args:\n",
    "            model_path: Model save path\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            print(\"Error: Model not trained yet!\")\n",
    "            return False\n",
    "\n",
    "        model_data = {\n",
    "            'pca': self.pca,\n",
    "            'scaler': self.scaler,\n",
    "            'face_features': self.face_features,\n",
    "            'face_labels': self.face_labels,\n",
    "            'face_info': self.face_info,\n",
    "            'person_id_map': self.person_id_map,\n",
    "            'n_components': self.n_components,\n",
    "            'mean_face': self.mean_face,\n",
    "            'eigenfaces': self.eigenfaces,\n",
    "            'face_shape': self.face_shape,\n",
    "            'training_date': datetime.now().isoformat()\n",
    "        }\n",
    "\n",
    "        with open(model_path, 'wb') as f:\n",
    "            pickle.dump(model_data, f)\n",
    "\n",
    "        print(f\"Model saved to {model_path}\")\n",
    "        return True\n",
    "\n",
    "    def load_model(self, model_path):\n",
    "        \"\"\"\n",
    "        Load trained model with eigenfaces support\n",
    "\n",
    "        Args:\n",
    "            model_path: Model file path\n",
    "        \"\"\"\n",
    "        if not os.path.exists(model_path):\n",
    "            print(f\"Error: Model file {model_path} not found!\")\n",
    "            return False\n",
    "\n",
    "        with open(model_path, 'rb') as f:\n",
    "            model_data = pickle.load(f)\n",
    "\n",
    "        self.pca = model_data['pca']\n",
    "        self.scaler = model_data['scaler']\n",
    "        self.face_features = model_data['face_features']\n",
    "        self.face_labels = model_data['face_labels']\n",
    "        self.face_info = model_data['face_info']\n",
    "        self.person_id_map = model_data['person_id_map']\n",
    "        self.n_components = model_data['n_components']\n",
    "\n",
    "        # Load eigenfaces data if available\n",
    "        self.mean_face = model_data.get('mean_face', None)\n",
    "        self.eigenfaces = model_data.get('eigenfaces', None)\n",
    "        self.face_shape = model_data.get('face_shape', (64, 64))\n",
    "\n",
    "        self.is_trained = True\n",
    "\n",
    "        print(f\"Model loaded from {model_path}\")\n",
    "        print(f\"Training date: {model_data.get('training_date', 'Unknown')}\")\n",
    "        print(f\"Total faces: {len(self.face_features)}\")\n",
    "        print(f\"Total persons: {len(self.person_id_map)}\")\n",
    "        if self.eigenfaces is not None:\n",
    "            print(f\"Eigenfaces loaded: {len(self.eigenfaces)}\")\n",
    "\n",
    "        return True\n",
    "\n",
    "\n",
    "def train_person_model(person_name, base_dir):\n",
    "    \"\"\"\n",
    "    Train model for a specific person\n",
    "\n",
    "    Args:\n",
    "        person_name: Name of the person to train\n",
    "        base_dir: Base directory containing person folders\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== Training model for {person_name} ===\")\n",
    "\n",
    "    # Configure paths for this person\n",
    "    person_dir = os.path.join(base_dir, person_name)\n",
    "    json_file = os.path.join(person_dir, f\"{person_name}_faces_detection.json\")\n",
    "    model_path = os.path.join(person_dir, \"face_model.pkl\")\n",
    "\n",
    "    # Check if person directory exists\n",
    "    if not os.path.exists(person_dir):\n",
    "        print(f\"Error: Person directory {person_dir} not found!\")\n",
    "        return False\n",
    "\n",
    "    # Count face images for this person\n",
    "    trainer_temp = MultiFaceTrainer()\n",
    "    face_count = trainer_temp.count_face_images_in_directory(person_dir)\n",
    "\n",
    "    if face_count == 0:\n",
    "        print(f\"No face images found for {person_name}!\")\n",
    "        return False\n",
    "\n",
    "    # Generate JSON file if it doesn't exist\n",
    "    if not os.path.exists(json_file):\n",
    "        trainer_temp.generate_detection_json_for_person(person_name, person_dir)\n",
    "\n",
    "    # Set n_components based on face count (use face_count for this person)\n",
    "    optimal_components = face_count if face_count > 1 else 1\n",
    "    print(f\"Face images found for {person_name}: {face_count}\")\n",
    "    print(f\"Setting n_components to: {optimal_components}\")\n",
    "\n",
    "    # Create trainer with optimal n_components\n",
    "    trainer = MultiFaceTrainer(n_components=optimal_components)\n",
    "\n",
    "    # Load face images for this person only\n",
    "    num_faces = trainer.load_face_images_from_json(json_file, person_dir)\n",
    "    if num_faces == 0:\n",
    "        print(f\"No valid face images loaded for {person_name}!\")\n",
    "        return False\n",
    "\n",
    "    print(f\"Loaded {num_faces} face images for {person_name}\")\n",
    "\n",
    "    # Train PCA model\n",
    "    if trainer.train_pca_model():\n",
    "        # Save eigenfaces as images in person's directory\n",
    "        trainer.save_eigenfaces(person_dir)\n",
    "\n",
    "        # Save model in person's directory\n",
    "        trainer.save_model(model_path)\n",
    "        print(f\"Training completed successfully for {person_name}!\")\n",
    "        print(f\"Model saved to: {model_path}\")\n",
    "        print(f\"Eigenfaces and mean face saved to: {person_dir}\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"Training failed for {person_name}!\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Configure paths\n",
    "    base_dir = \"student_faces\"\n",
    "\n",
    "    # Check if base directory exists\n",
    "    if not os.path.exists(base_dir):\n",
    "        print(f\"Error: Base directory {base_dir} not found!\")\n",
    "        return\n",
    "\n",
    "    # Find all person directories\n",
    "    person_dirs = [d for d in os.listdir(base_dir)\n",
    "                   if os.path.isdir(os.path.join(base_dir, d))]\n",
    "\n",
    "    if not person_dirs:\n",
    "        print(f\"No person directories found in {base_dir}!\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(person_dirs)} person directories: {person_dirs}\")\n",
    "\n",
    "    # Train model for each person\n",
    "    successful_trainings = 0\n",
    "    failed_trainings = 0\n",
    "\n",
    "    for person_name in person_dirs:\n",
    "        try:\n",
    "            if train_person_model(person_name, base_dir):\n",
    "                successful_trainings += 1\n",
    "            else:\n",
    "                failed_trainings += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Error training model for {person_name}: {str(e)}\")\n",
    "            failed_trainings += 1\n",
    "\n",
    "    print(f\"\\n=== Training Summary ===\")\n",
    "    print(f\"Total persons processed: {len(person_dirs)}\")\n",
    "    print(f\"Successful trainings: {successful_trainings}\")\n",
    "    print(f\"Failed trainings: {failed_trainings}\")\n",
    "\n",
    "    if successful_trainings > 0:\n",
    "        print(f\"\\nModels saved in individual person directories under {base_dir}\")\n",
    "        print(f\"Each model can be used with scan-template scripts for person-specific recognition\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16b85ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
