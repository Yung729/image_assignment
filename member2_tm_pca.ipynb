{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ae052b0",
   "metadata": {},
   "source": [
    "Config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1606ab6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResultLogger initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from typing import Optional\n",
    "import logging\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "class ResultLogger:\n",
    "    \"\"\"\n",
    "    A utility class for saving verification results to individual member JSON files.\n",
    "    Each member gets their own result file that is overwritten on each run.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, results_directory: str = \"results\"):\n",
    "        \"\"\"\n",
    "        Initialize the ResultLogger.\n",
    "        \n",
    "        Args:\n",
    "            results_directory (str): Directory where result files will be saved\n",
    "        \"\"\"\n",
    "        self.results_dir = Path(results_directory)\n",
    "        self.results_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "    def save_result(self, \n",
    "                   member_name: str,\n",
    "                   student_id: str, \n",
    "                   score: float,\n",
    "                   runtime: float,\n",
    "                   timestamp: Optional[str] = None) -> bool:\n",
    "        \"\"\"\n",
    "        Save verification result to a member-specific JSON file.\n",
    "        \n",
    "        Args:\n",
    "            member_name (str): Name of the member/algorithm (e.g., \"Member1\", \"Member2\")\n",
    "            student_id (str): Student ID from QR code\n",
    "            score (float): Verification confidence score (0.0 to 1.0)\n",
    "            runtime (float): Total verification time in seconds\n",
    "            timestamp (str, optional): ISO timestamp. If None, uses current time.\n",
    "            \n",
    "        Returns:\n",
    "            bool: True if saved successfully, False otherwise\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Generate timestamp if not provided\n",
    "            if timestamp is None:\n",
    "                timestamp = datetime.now().isoformat()\n",
    "            \n",
    "            # Create result data\n",
    "            result_data = {\n",
    "                \"member\": member_name,\n",
    "                \"student_id\": student_id,\n",
    "                \"score\": round(score, 4),  # Round to 4 decimal places\n",
    "                \"runtime\": round(runtime, 4),  # Round to 4 decimal places\n",
    "                \"timestamp\": timestamp\n",
    "            }\n",
    "            \n",
    "            # Generate filename based on member name\n",
    "            filename = f\"{member_name.lower()}_results.json\"\n",
    "            filepath = self.results_dir / filename\n",
    "            \n",
    "            # Save to file (overwrite existing)\n",
    "            with open(filepath, 'w', encoding='utf-8') as f:\n",
    "                json.dump(result_data, f, indent=2, ensure_ascii=False)\n",
    "            \n",
    "            print(f\"✓ Result saved for {member_name}: Score={score:.3f}, Runtime={runtime:.3f}s\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"✗ Failed to save result for {member_name}: {e}\")\n",
    "            return False\n",
    "\n",
    "# Initialize the logger\n",
    "result_logger = ResultLogger()\n",
    "print(\"ResultLogger initialized successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "808f4045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports and Configuration\n",
    "import cv2\n",
    "from pyzbar.pyzbar import decode\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import hashlib\n",
    "import time\n",
    "from typing import Tuple, List, Optional, Dict, Any\n",
    "import logging\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "# GUI Specific Imports\n",
    "import customtkinter as ctk\n",
    "from PIL import Image, ImageTk\n",
    "from tkinter import messagebox\n",
    "from skimage.feature import local_binary_pattern\n",
    "\n",
    "import pyttsx3\n",
    "import threading\n",
    "from tkinter import Toplevel\n",
    "from queue import Queue, Empty\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    FACE_DB_PATH: str = \"student_faces\"\n",
    "    LOG_FILE: str = \"verification_log.json\"\n",
    "    STUDENT_DATA_FILE: str = \"student_database.json\"\n",
    "    SUPPORTED_EXTENSIONS: List[str] = None\n",
    "    \n",
    "    # Camera settings\n",
    "    CAMERA_WIDTH: int = 640\n",
    "    CAMERA_HEIGHT: int = 480\n",
    "    CAMERA_FPS: int = 25\n",
    "    \n",
    "    # Template Matching parameters\n",
    "    TM_SCALE_FACTORS: List[float] = None\n",
    "    TM_THRESHOLD: float = 0.6\n",
    "    TM_METHOD: int = cv2.TM_CCOEFF_NORMED\n",
    "    \n",
    "    # PCA parameters\n",
    "    PCA_COMPONENTS: int = 150\n",
    "    PCA_VARIANCE_RATIO: float = 0.95\n",
    "    \n",
    "    # Verification thresholds\n",
    "    MATCH_THRESHOLD: float = 0.7\n",
    "    MIN_KEYPOINTS: int = 15\n",
    "    MIN_GOOD_MATCHES: int = 10\n",
    "    REQUIRED_CONSECUTIVE: int = 3\n",
    "    LOWE_RATIO: float = 0.7\n",
    "    \n",
    "    # Quality thresholds\n",
    "    MIN_FACE_SIZE: int = 80\n",
    "    PREFERRED_FACE_SIZE: int = 120\n",
    "    MIN_PHOTOS_REQUIRED: int = 5\n",
    "    DEFAULT_PHOTOS_COUNT: int = 12\n",
    "\n",
    "    # NEW: Lighting adaptation parameters\n",
    "    BRIGHT_THRESHOLD: float = 180.0\n",
    "    DARK_THRESHOLD: float = 70.0\n",
    "    OVEREXPOSE_RATIO_THRESHOLD: float = 0.1\n",
    "    UNDEREXPOSE_RATIO_THRESHOLD: float = 0.1\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.SUPPORTED_EXTENSIONS is None:\n",
    "            self.SUPPORTED_EXTENSIONS = ['.jpg', '.jpeg', '.png', '.bmp']\n",
    "        if self.TM_SCALE_FACTORS is None:\n",
    "            self.TM_SCALE_FACTORS = [0.8, 0.9, 1.0, 1.1, 1.2]\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('system.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "435344bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StudentSystem:\n",
    "    def __init__(self, config: Config = None):\n",
    "        self.config = config or Config()\n",
    "        self._setup_directories()\n",
    "        self.load_student_data()\n",
    "        \n",
    "        self.models = {}  # Store loaded models for each student\n",
    "        self.face_size = (100, 100)  # Standard face size for template matching\n",
    "        self.verification_stats = {\n",
    "            'total_attempts': 0, 'successful_verifications': 0,\n",
    "            'failed_verifications': 0, 'avg_verification_time': 0.0\n",
    "        }\n",
    "        \n",
    "        logger.info(\"Student Verification System backend initialized\")\n",
    "\n",
    "    def _setup_directories(self):\n",
    "        Path(self.config.FACE_DB_PATH).mkdir(exist_ok=True)\n",
    "\n",
    "    def load_student_models(self, student_id: str) -> bool:\n",
    "        \"\"\"Load pre-trained model for a specific student (similar to scan-template-v4.py)\"\"\"\n",
    "        model_pattern = f\"student_faces/{student_id}/face_model.pkl\"\n",
    "        model_path = Path(model_pattern)\n",
    "        \n",
    "        if not model_path.exists():\n",
    "            logger.warning(f\"No pre-trained model found for student {student_id} at {model_path}\")\n",
    "            return False\n",
    "        \n",
    "        try:\n",
    "            # Load model data (contains PCA components already trained)\n",
    "            with open(model_path, 'rb') as f:\n",
    "                model_data = pickle.load(f)\n",
    "            \n",
    "            # Load detection data\n",
    "            detection_json_path = model_path.parent / f\"{student_id}_faces_detection.json\"\n",
    "            detection_data = None\n",
    "            if detection_json_path.exists():\n",
    "                with open(detection_json_path, 'r', encoding='utf-8') as f:\n",
    "                    detection_data = json.load(f)\n",
    "            \n",
    "            # Load template images (first 5 faces for better matching)\n",
    "            template_images = []\n",
    "            if detection_data and detection_data['faces']:\n",
    "                for i, face_data in enumerate(detection_data['faces'][:5]):\n",
    "                    template_path = face_data['image_path']\n",
    "                    if Path(template_path).exists():\n",
    "                        template_img = cv2.imread(template_path, cv2.IMREAD_GRAYSCALE)\n",
    "                        if template_img is not None:\n",
    "                            template_images.append({\n",
    "                                'image': template_img,\n",
    "                                'width': face_data['width'],\n",
    "                                'height': face_data['height']\n",
    "                            })\n",
    "            \n",
    "            self.models[student_id] = {\n",
    "                'model_data': model_data,\n",
    "                'detection_data': detection_data,\n",
    "                'template_images': template_images,\n",
    "                'model_path': str(model_path)\n",
    "            }\n",
    "            \n",
    "            face_count = len(model_data['face_features']) if model_data else 0\n",
    "            logger.info(f\"Loaded model for {student_id}: {face_count} faces, {len(template_images)} templates\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to load model for {student_id}: {e}\")\n",
    "            return False\n",
    "\n",
    "    def is_detection_in_corner(self, detection, frame_width, frame_height, corner_threshold=0.15, border_threshold=0.05):\n",
    "        \"\"\"Check if detection is in corner area or border area (from scan-template-v4.py)\"\"\"\n",
    "        x, y, w, h = detection['x'], detection['y'], detection['width'], detection['height']\n",
    "        \n",
    "        # Calculate corner boundaries\n",
    "        corner_w = int(frame_width * corner_threshold)\n",
    "        corner_h = int(frame_height * corner_threshold)\n",
    "        \n",
    "        # Calculate border boundaries\n",
    "        border_w = int(frame_width * border_threshold)\n",
    "        border_h = int(frame_height * border_threshold)\n",
    "        \n",
    "        # Check if detection center is in any corner\n",
    "        center_x = x + w // 2\n",
    "        center_y = y + h // 2\n",
    "        \n",
    "        # Check if detection touches any border\n",
    "        if (x < border_w or y < border_h or \n",
    "            (x + w) > (frame_width - border_w) or \n",
    "            (y + h) > (frame_height - border_h)):\n",
    "            return True\n",
    "        \n",
    "        # Check corners\n",
    "        corners = [\n",
    "            (center_x < corner_w and center_y < corner_h),  # Top-left\n",
    "            (center_x > (frame_width - corner_w) and center_y < corner_h),  # Top-right\n",
    "            (center_x < corner_w and center_y > (frame_height - corner_h)),  # Bottom-left\n",
    "            (center_x > (frame_width - corner_w) and center_y > (frame_height - corner_h))  # Bottom-right\n",
    "        ]\n",
    "        \n",
    "        return any(corners)\n",
    "\n",
    "    def template_match_all_models(self, frame, student_id: str):\n",
    "        \"\"\"Perform template matching using loaded model (adapted from scan-template-v4.py)\"\"\"\n",
    "        detected_faces = []\n",
    "        frame_height, frame_width = frame.shape[:2]\n",
    "        \n",
    "        if student_id not in self.models:\n",
    "            logger.warning(f\"No model loaded for student {student_id}\")\n",
    "            return detected_faces\n",
    "        \n",
    "        model_info = self.models[student_id]\n",
    "        template_images = model_info['template_images']\n",
    "        detection_data = model_info['detection_data']\n",
    "        \n",
    "        if not template_images or not detection_data:\n",
    "            return detected_faces\n",
    "            \n",
    "        # Get average face size from detection data\n",
    "        avg_width = np.mean([face['width'] for face in detection_data['faces']])\n",
    "        avg_height = np.mean([face['height'] for face in detection_data['faces']])\n",
    "        \n",
    "        best_match = None\n",
    "        best_score = 0.0\n",
    "        \n",
    "        # Try each template image\n",
    "        for template_info in template_images:\n",
    "            template = template_info['image']\n",
    "            \n",
    "            # Multi-scale template matching\n",
    "            for scale in [0.8, 1.0, 1.2]:\n",
    "                # Resize template\n",
    "                new_width = int(template.shape[1] * scale)\n",
    "                new_height = int(template.shape[0] * scale)\n",
    "                \n",
    "                if new_width < 20 or new_height < 20 or new_width > frame.shape[1] or new_height > frame.shape[0]:\n",
    "                    continue\n",
    "                    \n",
    "                scaled_template = cv2.resize(template, (new_width, new_height))\n",
    "                \n",
    "                # Template matching\n",
    "                result = cv2.matchTemplate(frame, scaled_template, cv2.TM_CCOEFF_NORMED)\n",
    "                _, max_val, _, max_loc = cv2.minMaxLoc(result)\n",
    "                \n",
    "                if max_val > best_score:\n",
    "                    candidate_match = {\n",
    "                        'x': max_loc[0],\n",
    "                        'y': max_loc[1],\n",
    "                        'width': new_width,\n",
    "                        'height': new_height,\n",
    "                        'student_id': student_id,\n",
    "                        'confidence': max_val,\n",
    "                        'scale': scale\n",
    "                    }\n",
    "                    \n",
    "                    # Check if detection is in corner - if so, skip it\n",
    "                    if not self.is_detection_in_corner(candidate_match, frame_width, frame_height):\n",
    "                        best_score = max_val\n",
    "                        best_match = candidate_match\n",
    "        \n",
    "        # Add best match if confidence is above threshold\n",
    "        if best_match and best_score > 0.6:\n",
    "            detected_faces.append(best_match)\n",
    "        \n",
    "        return detected_faces\n",
    "\n",
    "    def extract_face_features(self, face_img, model_data):\n",
    "        \"\"\"Extract face features using loaded model (from scan-template-v4.py)\"\"\"\n",
    "        if len(face_img.shape) == 3:\n",
    "            gray = cv2.cvtColor(face_img, cv2.COLOR_BGR2GRAY)\n",
    "        else:\n",
    "            gray = face_img\n",
    "        \n",
    "        resized = cv2.resize(gray, (64, 64))\n",
    "        flattened = resized.flatten().reshape(1, -1)\n",
    "        \n",
    "        scaled = model_data['scaler'].transform(flattened)\n",
    "        features = model_data['pca'].transform(scaled)\n",
    "        \n",
    "        return features[0]\n",
    "\n",
    "    def recognize_face_with_model(self, face_features, model_data, threshold=0.7):\n",
    "        \"\"\"Recognize face using loaded model (from scan-template-v4.py)\"\"\"\n",
    "        similarities = cosine_similarity([face_features], model_data['face_features'])[0]\n",
    "        max_idx = np.argmax(similarities)\n",
    "        max_similarity = similarities[max_idx]\n",
    "        \n",
    "        if max_similarity >= threshold:\n",
    "            person_id = model_data['face_labels'][max_idx]\n",
    "            person_name = \"unknown\"\n",
    "            for name, pid in model_data['person_id_map'].items():\n",
    "                if pid == person_id:\n",
    "                    person_name = name\n",
    "                    break\n",
    "            return person_id, person_name, max_similarity\n",
    "        else:\n",
    "            return -1, \"unknown\", max_similarity\n",
    "\n",
    "    def recognize_face_all_models(self, face_img, student_id: str, threshold=0.8):\n",
    "        \"\"\"Recognize face using loaded model (adapted from scan-template-v4.py)\"\"\"\n",
    "        if student_id not in self.models:\n",
    "            return -1, \"unknown\", 0.0\n",
    "        \n",
    "        model_info = self.models[student_id]\n",
    "        model_data = model_info['model_data']\n",
    "        \n",
    "        if model_data is None:\n",
    "            return -1, \"unknown\", 0.0\n",
    "        \n",
    "        try:\n",
    "            features = self.extract_face_features(face_img, model_data)\n",
    "            person_id, recognized_name, confidence = self.recognize_face_with_model(features, model_data, threshold)\n",
    "            \n",
    "            logger.info(f\"Recognition result: ID={person_id}, Name={recognized_name}, Confidence={confidence:.3f}\")\n",
    "            \n",
    "            return person_id, recognized_name, confidence\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error recognizing face for student {student_id}: {e}\")\n",
    "            return -1, \"unknown\", 0.0\n",
    "\n",
    "    def log_verification(self, student_id: str, name: str, program: str, success: bool, \n",
    "                         timestamp: str, score: float = 0.0, verification_time: float = 0.0):\n",
    "        log_entry = {\n",
    "            \"student_id\": student_id, \"name\": name, \"program\": program, \"success\": success,\n",
    "            \"timestamp\": timestamp, \"score\": score, \"verification_time\": verification_time,\n",
    "            \"session_id\": hashlib.md5(f\"{timestamp}{student_id}\".encode()).hexdigest()[:8]\n",
    "        }\n",
    "        try:\n",
    "            logs = []\n",
    "            if Path(self.config.LOG_FILE).exists():\n",
    "                with open(self.config.LOG_FILE, 'r', encoding='utf-8') as f:\n",
    "                    logs = json.load(f)\n",
    "            logs.append(log_entry)\n",
    "            if len(logs) > 1000:\n",
    "                logs = logs[-1000:]\n",
    "            with open(self.config.LOG_FILE, 'w', encoding='utf-8') as f:\n",
    "                json.dump(logs, f, indent=2, ensure_ascii=False)\n",
    "            status = \"SUCCESS\" if success else \"FAILED\"\n",
    "            logger.info(f\"Verification logged: {name} - {status} (Score: {score:.3f})\")\n",
    "        except IOError as e:\n",
    "            logger.error(f\"Error logging verification: {e}\")\n",
    "\n",
    "    # Keep existing methods unchanged\n",
    "    def load_student_data(self):\n",
    "        try:\n",
    "            if Path(self.config.STUDENT_DATA_FILE).exists():\n",
    "                with open(self.config.STUDENT_DATA_FILE, 'r', encoding='utf-8') as f:\n",
    "                    self.student_data = json.load(f)\n",
    "                logger.info(f\"Loaded data for {len(self.student_data)} students\")\n",
    "            else:\n",
    "                self.student_data = {}\n",
    "                logger.info(\"No existing student data found, starting fresh\")\n",
    "        except (json.JSONDecodeError, IOError) as e:\n",
    "            logger.error(f\"Error loading student data: {e}\")\n",
    "            self.student_data = {}\n",
    "\n",
    "    def get_student_info(self, student_id: str) -> Optional[Dict[str, Any]]:\n",
    "        return self.student_data.get(student_id)\n",
    "\n",
    "    def validate_qr_data(self, qr_data: str) -> Tuple[Optional[str], Optional[str], Optional[str]]:\n",
    "        student_id = qr_data.strip()\n",
    "        student_info = self.get_student_info(student_id)\n",
    "        if student_info:\n",
    "            name = student_info.get(\"name\", \"N/A\")\n",
    "            program = student_info.get(\"program\", \"N/A\")\n",
    "            logger.info(f\"QR ID '{student_id}' found in database for student: {name}\")\n",
    "            return student_id, name, program\n",
    "        else:\n",
    "            logger.warning(f\"QR ID '{student_id}' not found in the student database.\")\n",
    "            return None, None, None\n",
    "\n",
    "    def load_registered_faces(self, student_id: str) -> List[np.ndarray]:\n",
    "        folder = Path(self.config.FACE_DB_PATH) / student_id\n",
    "        if not folder.is_dir(): return []\n",
    "        images = []\n",
    "        for file_path in folder.glob(\"*\"):\n",
    "            if file_path.suffix.lower() in self.config.SUPPORTED_EXTENSIONS:\n",
    "                try:\n",
    "                    img = cv2.imread(str(file_path))\n",
    "                    if img is not None and img.size > 0:\n",
    "                        images.append(img)\n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"Failed to load image {file_path}: {e}\")\n",
    "        logger.info(f\"Loaded {len(images)} face images for student {student_id}\")\n",
    "        return images\n",
    "\n",
    "    def preprocess_face(self, face_img: np.ndarray) -> np.ndarray:\n",
    "        if len(face_img.shape) == 3:\n",
    "            gray = cv2.cvtColor(face_img, cv2.COLOR_BGR2GRAY)\n",
    "        else:\n",
    "            gray = face_img.copy()\n",
    "\n",
    "        resized = cv2.resize(gray, (220, 220), interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "        # Adaptive lighting analysis\n",
    "        mean_brightness = np.mean(resized)\n",
    "        std_brightness = np.std(resized)\n",
    "        overexposed_pixels = np.sum(resized >= 240) / resized.size\n",
    "        underexposed_pixels = np.sum(resized <= 20) / resized.size\n",
    "    \n",
    "        # Adaptive brightness correction\n",
    "        if mean_brightness > 180 or overexposed_pixels > 0.1:\n",
    "            # Very bright/overexposed - reduce brightness and enhance shadows\n",
    "            alpha, beta = 0.7, -25\n",
    "            resized = cv2.convertScaleAbs(resized, alpha=alpha, beta=beta)\n",
    "            gamma = 1.3\n",
    "            resized = np.power(resized / 255.0, gamma) * 255.0\n",
    "            resized = resized.astype(np.uint8)\n",
    "        elif mean_brightness < 70 or underexposed_pixels > 0.1:\n",
    "            # Dark/underexposed - increase brightness\n",
    "            alpha, beta = 1.3, 25\n",
    "            resized = cv2.convertScaleAbs(resized, alpha=alpha, beta=beta)\n",
    "            gamma = 0.7\n",
    "            resized = np.power(resized / 255.0, gamma) * 255.0\n",
    "            resized = resized.astype(np.uint8)\n",
    "    \n",
    "        # Adaptive CLAHE based on contrast\n",
    "        if std_brightness < 30:  # Low contrast\n",
    "            clip_limit, tile_size = 3.0, (8, 8)\n",
    "        elif std_brightness > 60:  # High contrast\n",
    "            clip_limit, tile_size = 1.5, (12, 12)\n",
    "        else:  # Normal contrast\n",
    "            clip_limit, tile_size = 2.0, (8, 8)\n",
    "    \n",
    "        clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_size)\n",
    "        enhanced = clahe.apply(resized)\n",
    "    \n",
    "        # Create a sharpening kernel\n",
    "        kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])\n",
    "        sharpened = cv2.filter2D(enhanced, -1, kernel)\n",
    "    \n",
    "        # Blend original enhanced with sharpened (80% enhanced, 20% sharpened)\n",
    "        blended = cv2.addWeighted(enhanced, 0.8, sharpened, 0.2, 0)\n",
    "    \n",
    "        # Final normalization\n",
    "        normalized = cv2.normalize(blended, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    \n",
    "        return normalized.astype(np.uint8)\n",
    "\n",
    "    \n",
    "    def calculate_pca_similarity_score(\n",
    "        self, face1_features: np.ndarray, face2_features: np.ndarray\n",
    "    ) -> float:\n",
    "        \"\"\"\n",
    "        Calculate similarity score using PCA features and cosine similarity\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Ensure features are 2D arrays\n",
    "            if face1_features.ndim == 1:\n",
    "                face1_features = face1_features.reshape(1, -1)\n",
    "            if face2_features.ndim == 1:\n",
    "                face2_features = face2_features.reshape(1, -1)\n",
    "            \n",
    "            # Calculate cosine similarity\n",
    "            similarity = cosine_similarity(face1_features, face2_features)[0, 0]\n",
    "            \n",
    "            # Convert to positive score (cosine similarity ranges from -1 to 1)\n",
    "            score = (similarity + 1) / 2\n",
    "            \n",
    "            logger.info(f\"PCA similarity score: {score:.4f} (cosine: {similarity:.4f})\")\n",
    "            return float(score)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error calculating PCA similarity: {e}\")\n",
    "            return 0.0\n",
    "\n",
    "    def extract_pca_features(self, face_img: np.ndarray) -> Optional[np.ndarray]:\n",
    "        \"\"\"Extract PCA features from a face image\"\"\"\n",
    "        try:\n",
    "            if self.pca is None:\n",
    "                logger.warning(\"PCA not initialized\")\n",
    "                return None\n",
    "            \n",
    "            # Resize to standard size and flatten\n",
    "            resized_face = cv2.resize(face_img, self.face_size)\n",
    "            flattened = resized_face.flatten().reshape(1, -1)\n",
    "            \n",
    "            # Transform using PCA\n",
    "            features = self.pca.transform(flattened)\n",
    "            return features[0]\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error extracting PCA features: {e}\")\n",
    "            return None\n",
    "\n",
    "    def export_verification_report(self) -> str: # MODIFIED: Returns status string for GUI\n",
    "        if not Path(self.config.LOG_FILE).exists():\n",
    "            return \"No verification logs found to export.\"\n",
    "        try:\n",
    "            with open(self.config.LOG_FILE, 'r', encoding='utf-8') as f: logs = json.load(f)\n",
    "            if not logs: return \"No verification data to export.\"\n",
    "            \n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            report_file = f\"verification_report_{timestamp}.json\"\n",
    "            \n",
    "            total = len(logs)\n",
    "            successful = sum(1 for log in logs if log['success'])\n",
    "            success_rate = (successful / total * 100) if total > 0 else 0\n",
    "            \n",
    "            report = {\n",
    "                'generated_at': datetime.now().isoformat(),\n",
    "                'summary': {\n",
    "                    'total_attempts': total,\n",
    "                    'successful_verifications': successful,\n",
    "                    'success_rate_percentage': round(success_rate, 2),\n",
    "                },\n",
    "                'recent_logs': logs[-50:]\n",
    "            }\n",
    "            with open(report_file, 'w', encoding='utf-8') as f:\n",
    "                json.dump(report, f, indent=2, ensure_ascii=False)\n",
    "            return f\"Report successfully exported to {report_file}\"\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error generating report: {e}\")\n",
    "            return f\"Failed to generate report: {e}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d255ca8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobustTTS:\n",
    "    def __init__(self):\n",
    "        self.speech_queue = Queue()\n",
    "        self.worker_thread = threading.Thread(target=self._worker_loop, daemon=True)\n",
    "        self.worker_thread.start()\n",
    "        logger.info(\"RobustTTS worker thread started.\")\n",
    "\n",
    "    def _worker_loop(self):\n",
    "        \"\"\"\n",
    "        Processes speech requests from the queue.\n",
    "        Each request gets a new, temporary TTS engine.\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            try:\n",
    "                # Wait indefinitely for a new speech task\n",
    "                text = self.speech_queue.get()\n",
    "\n",
    "                # A special signal to terminate the thread\n",
    "                if text is None:\n",
    "                    break\n",
    "\n",
    "                # --- The Core Fix ---\n",
    "                # Create a new engine instance for this specific text.\n",
    "                # This is the key to avoiding state-related errors.\n",
    "                engine = pyttsx3.init(driverName='sapi5')\n",
    "\n",
    "                # Configure the engine (optional but recommended)\n",
    "                voices = engine.getProperty('voices')\n",
    "                if voices:\n",
    "                    for voice in voices:\n",
    "                        if 'female' in voice.name.lower() or 'zira' in voice.name.lower():\n",
    "                            engine.setProperty('voice', voice.id)\n",
    "                            break\n",
    "                engine.setProperty('rate', 155)\n",
    "                engine.setProperty('volume', 0.9)\n",
    "\n",
    "                # Speak the text\n",
    "                engine.say(text)\n",
    "                engine.runAndWait()\n",
    "\n",
    "                # Cleanly shut down the temporary engine\n",
    "                del engine\n",
    "\n",
    "            except Empty:\n",
    "                # This part is unlikely to be reached with a blocking .get()\n",
    "                # but is good practice.\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                # Log any errors that occur during TTS synthesis\n",
    "                logger.error(f\"TTS worker loop error: {e}\")\n",
    "\n",
    "    def speak(self, text: str):\n",
    "        \"\"\"\n",
    "        Adds a text string to the speech queue to be spoken.\n",
    "        This method is non-blocking.\n",
    "        \"\"\"\n",
    "        if text and text.strip():\n",
    "            # Clear any pending speech requests to say the newest one\n",
    "            while not self.speech_queue.empty():\n",
    "                try:\n",
    "                    self.speech_queue.get_nowait()\n",
    "                except Empty:\n",
    "                    break\n",
    "            # Add the new text to the queue\n",
    "            self.speech_queue.put(text.strip())\n",
    "\n",
    "    def cleanup(self):\n",
    "        \"\"\"\n",
    "        Sends a signal to the worker thread to terminate gracefully.\n",
    "        Call this when the application is closing.\n",
    "        \"\"\"\n",
    "        logger.info(\"Cleaning up TTS system...\")\n",
    "        self.speech_queue.put(None)  # Sentinel value to stop the worker\n",
    "        self.worker_thread.join(timeout=2.0) # Wait for thread to finish\n",
    "        logger.info(\"TTS system cleaned up.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bd30a262",
   "metadata": {},
   "outputs": [],
   "source": [
    "class App(ctk.CTk):\n",
    "    def __init__(self, student_system: StudentSystem):\n",
    "        super().__init__()\n",
    "        self.system = student_system\n",
    "        \n",
    "        self.tts_system = RobustTTS()\n",
    "\n",
    "        self.verification_start_time = None\n",
    "        self.member_name = \"Member1\"\n",
    "\n",
    "        self.title(\"🎓 Student Verification System\")\n",
    "        self.geometry(\"1100x720\")\n",
    "        ctk.set_appearance_mode(\"Dark\")\n",
    "        ctk.set_default_color_theme(\"blue\")\n",
    "        \n",
    "        # --- App State ---\n",
    "        self.cap = None\n",
    "        self.verification_active = False\n",
    "        self.current_student_id = None\n",
    "        self.current_student_name = None\n",
    "        self.current_student_program = None\n",
    "        self.reference_data = []\n",
    "        self.consecutive_matches = 0\n",
    "        self.best_score = 0.0\n",
    "        self.last_known_face = None\n",
    "        self.frame_count = 0\n",
    "        self.verification_step = \"idle\" # States: idle, qr_scan, face_verify\n",
    "        self.pending_preparation = None  # Track pending preparation callback\n",
    "        self.qr_detected = False # Prevent multiple QR detections\n",
    "        \n",
    "        # --- Layout ---\n",
    "        self.grid_columnconfigure(1, weight=1)\n",
    "        self.grid_rowconfigure(0, weight=1)\n",
    "\n",
    "        # --- Sidebar Frame ---\n",
    "        self.sidebar_frame = ctk.CTkFrame(self, width=200, corner_radius=0)\n",
    "        self.sidebar_frame.grid(row=0, column=0, rowspan=4, sticky=\"nsew\")\n",
    "        self.sidebar_frame.grid_rowconfigure(5, weight=1)\n",
    "        \n",
    "        self.logo_label = ctk.CTkLabel(self.sidebar_frame, text=\"Main Menu\", font=ctk.CTkFont(size=20, weight=\"bold\"))\n",
    "        self.logo_label.grid(row=0, column=0, padx=20, pady=(20, 10))\n",
    "        \n",
    "        self.verify_button = ctk.CTkButton(self.sidebar_frame, text=\"Verify Student\", command=self.verify_student_frame_event)\n",
    "        self.verify_button.grid(row=1, column=0, padx=20, pady=10)\n",
    "\n",
    "        self.logs_button = ctk.CTkButton(self.sidebar_frame, text=\"View Logs\", command=self.view_logs_frame_event)\n",
    "        self.logs_button.grid(row=2, column=0, padx=20, pady=10)\n",
    "\n",
    "        self.export_button = ctk.CTkButton(self.sidebar_frame, text=\"Export Report\", command=self.export_report_event)\n",
    "        self.export_button.grid(row=3, column=0, padx=20, pady=10)\n",
    "\n",
    "        self.exit_button = ctk.CTkButton(self.sidebar_frame, text=\"Exit\", fg_color=\"transparent\", border_width=2, text_color=(\"gray10\", \"#DCE4EE\"), command=self.on_closing)\n",
    "        self.exit_button.grid(row=6, column=0, padx=20, pady=20, sticky=\"s\")\n",
    "        \n",
    "        # --- Verification Frame ---\n",
    "        self.verify_frame = ctk.CTkFrame(self, corner_radius=0, fg_color=\"transparent\")\n",
    "        self.verify_frame.grid_columnconfigure(0, weight=1)\n",
    "        \n",
    "        self.camera_label = ctk.CTkLabel(self.verify_frame, text=\"\")\n",
    "        self.camera_label.grid(row=0, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.status_label = ctk.CTkLabel(self.verify_frame, text=\"Welcome! Click 'Start Verification' to begin.\", font=ctk.CTkFont(size=16))\n",
    "        self.status_label.grid(row=1, column=0, padx=10, pady=5)\n",
    "        \n",
    "        self.info_label = ctk.CTkLabel(self.verify_frame, text=\"\", font=ctk.CTkFont(size=14))\n",
    "        self.info_label.grid(row=2, column=0, padx=10, pady=5)\n",
    "        \n",
    "        self.progress_bar = ctk.CTkProgressBar(self.verify_frame, width=300)\n",
    "        self.progress_bar.set(0) # Start it at 0\n",
    "        self.progress_bar.grid(row=3, column=0, padx=10, pady=5)\n",
    "\n",
    "        self.start_button = ctk.CTkButton(self.verify_frame, text=\"Start Verification\", command=self.start_verification_process)\n",
    "        self.start_button.grid(row=4, column=0, padx=10, pady=10)\n",
    "\n",
    "        # --- Logs Frame ---\n",
    "        self.logs_frame = ctk.CTkFrame(self, corner_radius=0, fg_color=\"transparent\")\n",
    "        self.logs_frame.grid_columnconfigure(0, weight=1)\n",
    "        self.logs_frame.grid_rowconfigure(0, weight=1)\n",
    "        self.log_textbox = ctk.CTkTextbox(self.logs_frame, width=700, font=(\"Courier New\", 12))\n",
    "        self.log_textbox.grid(row=0, column=0, padx=20, pady=20, sticky=\"nsew\")\n",
    "        \n",
    "\n",
    "\n",
    "        # --- Initial Setup ---\n",
    "        self.select_frame_by_name(\"verify\")\n",
    "        self.protocol(\"WM_DELETE_WINDOW\", self.on_closing)\n",
    "\n",
    "    def setup_tts_engine(self):\n",
    "        \"\"\"Configure the text-to-speech engine\"\"\"\n",
    "        try:\n",
    "            # Set properties for better voice quality\n",
    "            voices = self.tts_engine.getProperty('voices')\n",
    "            if voices:\n",
    "                # Try to use a female voice if available, otherwise use default\n",
    "                for voice in voices:\n",
    "                    if 'female' in voice.name.lower() or 'zira' in voice.name.lower():\n",
    "                        self.tts_engine.setProperty('voice', voice.id)\n",
    "                        break\n",
    "            \n",
    "            # Set speech rate (words per minute)\n",
    "            self.tts_engine.setProperty('rate', 150)  # Slower for clarity\n",
    "            \n",
    "            # Set volume (0.0 to 1.0)\n",
    "            self.tts_engine.setProperty('volume', 0.8)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"TTS engine setup warning: {e}\")\n",
    "\n",
    "    def speak_text(self, text):\n",
    "        self.tts_system.speak(text)\n",
    "\n",
    "    def show_student_details_screen(self, student_id: str, verification_score: float):\n",
    "        \"\"\"\n",
    "        Display a detailed screen with student information and voice announcement\n",
    "        \n",
    "        Args:\n",
    "            student_id (str): The student ID\n",
    "            verification_score (float): The final verification score\n",
    "        \"\"\"\n",
    "        student_info = self.system.get_student_info(student_id)\n",
    "        if not student_info:\n",
    "            logger.error(f\"No student info found for ID: {student_id}\")\n",
    "            return\n",
    "        \n",
    "        # Create a new window for student details\n",
    "        details_window = Toplevel(self)\n",
    "        details_window.title(\"✅ Verification Successful\")\n",
    "        details_window.geometry(\"600x500\")\n",
    "        details_window.configure(bg='#1a1a1a')\n",
    "        details_window.resizable(False, False)\n",
    "        \n",
    "        # Make window modal and center it\n",
    "        details_window.transient(self)\n",
    "        details_window.grab_set()\n",
    "        \n",
    "        # Center the window\n",
    "        details_window.update_idletasks()\n",
    "        x = (details_window.winfo_screenwidth() // 2) - (600 // 2)\n",
    "        y = (details_window.winfo_screenheight() // 2) - (500 // 2)\n",
    "        details_window.geometry(f\"1200x700+{x}+{y}\")\n",
    "        \n",
    "        # Create main frame\n",
    "        main_frame = ctk.CTkFrame(details_window, fg_color=\"transparent\")\n",
    "        main_frame.pack(fill=\"both\", expand=True, padx=20, pady=20)\n",
    "        \n",
    "        # Success header\n",
    "        success_label = ctk.CTkLabel(\n",
    "            main_frame, \n",
    "            text=\"🎉 VERIFICATION SUCCESSFUL 🎉\",\n",
    "            font=ctk.CTkFont(size=24, weight=\"bold\"),\n",
    "            text_color=\"#00ff00\"\n",
    "        )\n",
    "        success_label.pack(pady=(0, 20))\n",
    "        \n",
    "        # Student photo - load from card_photos folder\n",
    "        photo_frame = ctk.CTkFrame(main_frame, width=180, height=200, fg_color=\"#2b2b2b\")\n",
    "        photo_frame.pack(pady=(0, 20))\n",
    "        photo_frame.pack_propagate(False)  # Maintain frame size\n",
    "        \n",
    "        # Try to load student photo from card_photos folder\n",
    "        photo_loaded = False\n",
    "        try:\n",
    "            # Look for photo in card_photos folder with student ID as filename\n",
    "            card_photos_folder = Path(\"card_photos\")\n",
    "            \n",
    "            # Try different extensions\n",
    "            for ext in ['.jpg', '.jpeg', '.png', '.bmp']:\n",
    "                photo_path = card_photos_folder / f\"{student_id}{ext}\"\n",
    "                if photo_path.exists():\n",
    "                    img = cv2.imread(str(photo_path))\n",
    "                    if img is not None:\n",
    "                        # Convert BGR to RGB\n",
    "                        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                        \n",
    "                        # Resize image to fit frame (170x190 with padding)\n",
    "                        img_pil = Image.fromarray(img_rgb)\n",
    "                        img_pil = img_pil.resize((170, 190), Image.Resampling.LANCZOS)\n",
    "                        \n",
    "                        # Create CTk image\n",
    "                        photo_ctk = ctk.CTkImage(\n",
    "                            light_image=img_pil, \n",
    "                            dark_image=img_pil, \n",
    "                            size=(170, 190)\n",
    "                        )\n",
    "                        \n",
    "                        # Display the photo\n",
    "                        photo_label = ctk.CTkLabel(\n",
    "                            photo_frame, \n",
    "                            image=photo_ctk,\n",
    "                            text=\"\"\n",
    "                        )\n",
    "                        photo_label.pack(expand=True, padx=5, pady=5)\n",
    "                        photo_loaded = True\n",
    "                        logger.info(f\"Loaded student photo: {photo_path}\")\n",
    "                        break\n",
    "                        \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Could not load student photo: {e}\")\n",
    "        \n",
    "        # If no photo loaded, show placeholder\n",
    "        if not photo_loaded:\n",
    "            photo_label = ctk.CTkLabel(\n",
    "                photo_frame, \n",
    "                text=\"👤\\nNo Photo\\nAvailable\",\n",
    "                font=ctk.CTkFont(size=14),\n",
    "                text_color=\"#cccccc\"\n",
    "            )\n",
    "            photo_label.pack(expand=True)\n",
    "            logger.info(f\"No photo found for student {student_id} in card_photos folder\")\n",
    "        \n",
    "        # Student details frame\n",
    "        details_frame = ctk.CTkFrame(main_frame, fg_color=\"#2b2b2b\")\n",
    "        details_frame.pack(fill=\"x\", pady=(0, 20))\n",
    "        \n",
    "        # Extract student information\n",
    "        name = student_info.get(\"name\", \"N/A\")\n",
    "        program = student_info.get(\"program\", \"N/A\")\n",
    "        batch = student_info.get(\"batch\", \"N/A\")\n",
    "        academic_performance = student_info.get(\"academic_performance\", \"N/A\")\n",
    "        cgpa = student_info.get(\"cgpa\", \"N/A\")\n",
    "        \n",
    "        # Create detail labels\n",
    "        details_data = [\n",
    "            (\"👤 Name:\", name),\n",
    "            (\"📚 Program:\", program),\n",
    "            (\"🎓 Batch:\", f\"20{batch}\" if batch.isdigit() else batch),\n",
    "            (\"⭐ Academic Performance:\", academic_performance),\n",
    "            (\"📊 CGPA:\", cgpa),\n",
    "            (\"🔍 Verification Score:\", f\"{verification_score*100:.1f}%\")\n",
    "        ]\n",
    "        \n",
    "        for i, (label, value) in enumerate(details_data):\n",
    "            detail_frame = ctk.CTkFrame(details_frame, fg_color=\"transparent\")\n",
    "            detail_frame.pack(fill=\"x\", padx=20, pady=5)\n",
    "            \n",
    "            label_widget = ctk.CTkLabel(\n",
    "                detail_frame,\n",
    "                text=label,\n",
    "                font=ctk.CTkFont(size=14, weight=\"bold\"),\n",
    "                anchor=\"w\"\n",
    "            )\n",
    "            label_widget.pack(side=\"left\", fill=\"x\", expand=True)\n",
    "            \n",
    "            value_widget = ctk.CTkLabel(\n",
    "                detail_frame,\n",
    "                text=str(value),\n",
    "                font=ctk.CTkFont(size=14),\n",
    "                text_color=\"#00bfff\",\n",
    "                anchor=\"e\"\n",
    "            )\n",
    "            value_widget.pack(side=\"right\")\n",
    "        \n",
    "        # Buttons frame\n",
    "        button_frame = ctk.CTkFrame(main_frame, fg_color=\"transparent\")\n",
    "        button_frame.pack(fill=\"x\", pady=(10, 0))\n",
    "        \n",
    "        # Close button\n",
    "        close_button = ctk.CTkButton(\n",
    "            button_frame,\n",
    "            text=\"✓ Close\",\n",
    "            command=details_window.destroy,\n",
    "            fg_color=\"#2196F3\",\n",
    "            hover_color=\"#1976D2\"\n",
    "        )\n",
    "        close_button.pack(side=\"right\")\n",
    "        \n",
    "        # Auto-close timer (optional)\n",
    "        def auto_close():\n",
    "            try:\n",
    "                if details_window.winfo_exists():\n",
    "                    details_window.destroy()\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # Auto close after 15 seconds\n",
    "        details_window.after(15000, auto_close)\n",
    "        \n",
    "        # Make initial voice announcement\n",
    "        self.announce_student_details(name, program, batch, academic_performance)\n",
    "        \n",
    "        return details_window\n",
    "\n",
    "    def announce_student_details(self, name: str, program: str, batch: str, academic_performance: str):\n",
    "        \"\"\"Create and speak the announcement text\"\"\"\n",
    "        # Create a natural announcement\n",
    "        announcement_parts = [\n",
    "            f\"Verification successful.\",\n",
    "            f\"Welcome, {name}.\",\n",
    "            f\"Program: {program}.\",\n",
    "            f\"Batch 20{batch}.\" if batch.isdigit() else f\"Batch {batch}.\",\n",
    "            f\"Academic performance: {academic_performance}.\",\n",
    "            \"Access granted. Have a great day!\"\n",
    "        ]\n",
    "        \n",
    "        announcement_text = \" \".join(announcement_parts)\n",
    "        \n",
    "        # Log the announcement\n",
    "        logger.info(f\"Voice announcement: {announcement_text}\")\n",
    "        \n",
    "        # Speak the announcement\n",
    "        self.speak_text(announcement_text)\n",
    "\n",
    "    def select_frame_by_name(self, name):\n",
    "        # Hide all frames\n",
    "        self.verify_frame.grid_remove()\n",
    "        self.logs_frame.grid_remove()\n",
    "        \n",
    "        # Show the selected frame\n",
    "        if name == \"verify\":\n",
    "            self.verify_frame.grid(row=0, column=1, sticky=\"nsew\")\n",
    "        elif name == \"logs\":\n",
    "            self.logs_frame.grid(row=0, column=1, sticky=\"nsew\")\n",
    "            \n",
    "    def verify_student_frame_event(self):\n",
    "        self.select_frame_by_name(\"verify\")\n",
    "\n",
    "    def view_logs_frame_event(self):\n",
    "        self.select_frame_by_name(\"logs\")\n",
    "        logs = self.system.view_logs()\n",
    "        self.log_textbox.configure(state=\"normal\")\n",
    "        self.log_textbox.delete(\"1.0\", \"end\")\n",
    "        self.log_textbox.insert(\"1.0\", logs)\n",
    "        self.log_textbox.configure(state=\"disabled\")\n",
    "        \n",
    "\n",
    "    def export_report_event(self):\n",
    "        message = self.system.export_verification_report()\n",
    "        messagebox.showinfo(\"Export Report\", message)\n",
    "        \n",
    "    def start_verification_process(self):\n",
    "        if self.verification_active: return\n",
    "        \n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "        if not self.cap.isOpened():\n",
    "            messagebox.showerror(\"Camera Error\", \"Cannot open camera.\")\n",
    "            return\n",
    "\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, self.system.config.CAMERA_WIDTH)\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, self.system.config.CAMERA_HEIGHT)\n",
    "        \n",
    "        self.qr_detected = False\n",
    "        self.pending_preparation = None\n",
    "\n",
    "        self.verification_active = True\n",
    "        self.verification_step = \"qr_scan\"\n",
    "        self.start_button.configure(state=\"disabled\", text=\"Verification in Progress...\")\n",
    "        self.verification_start_time = time.time()\n",
    "        \n",
    "        self.update_frame()\n",
    "\n",
    "    def stop_verification_process(self):\n",
    "        self.verification_active = False\n",
    "        self.verification_step = \"idle\"\n",
    "        if self.pending_preparation is not None:\n",
    "            self.after_cancel(self.pending_preparation)\n",
    "            self.pending_preparation = None\n",
    "\n",
    "        if self.cap:\n",
    "            self.cap.release()\n",
    "            self.cap = None\n",
    "        self.start_button.configure(state=\"normal\", text=\"Start Verification\")\n",
    "        # Reset state for next run\n",
    "        self.current_student_id = None\n",
    "        self.current_student_name = None\n",
    "        self.current_student_program = None\n",
    "        self.reference_data = []\n",
    "        self.consecutive_matches = 0\n",
    "        self.best_score = 0.0\n",
    "        self.last_known_face = None\n",
    "        self.frame_count = 0\n",
    "        self.progress_bar.set(0)\n",
    "        self.qr_detected = False\n",
    "\n",
    "    def update_frame(self):\n",
    "        if not self.verification_active:\n",
    "            return\n",
    "\n",
    "        ret, frame = self.cap.read()\n",
    "        if not ret:\n",
    "            self.after(15, self.update_frame)\n",
    "            return\n",
    "        \n",
    "        frame = cv2.flip(frame, 1)\n",
    "        \n",
    "        if self.verification_step == \"qr_scan\":\n",
    "            self.handle_qr_scan(frame)\n",
    "        elif self.verification_step == \"face_verify\":\n",
    "            self.handle_face_verify(frame)\n",
    "        \n",
    "        # Convert frame for display\n",
    "        img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        img = Image.fromarray(img)\n",
    "        ctk_img = ctk.CTkImage(light_image=img, dark_image=img, size=(self.system.config.CAMERA_WIDTH, self.system.config.CAMERA_HEIGHT))\n",
    "        self.camera_label.configure(image=ctk_img)\n",
    "        self.camera_label.image = ctk_img\n",
    "\n",
    "        self.after(15, self.update_frame) # Schedule next update\n",
    "\n",
    "    def handle_qr_scan(self, frame):\n",
    "        self.status_label.configure(text=\"📱 Step 1: Scan Student QR Code\")\n",
    "        self.info_label.configure(text=\"Position the QR code in the camera view.\")\n",
    "\n",
    "        decoded_objects = decode(frame)\n",
    "        for obj in decoded_objects:\n",
    "            qr_data = obj.data.decode(\"utf-8\")\n",
    "            student_id, name, program = self.system.validate_qr_data(qr_data)\n",
    "            \n",
    "            if all([student_id, name, program]):\n",
    "                self.current_student_id = student_id\n",
    "                self.current_student_name = name\n",
    "                self.current_student_program = program\n",
    "                self.qr_detected = True  # Prevent multiple detections\n",
    "\n",
    "                # Draw on frame\n",
    "                points = obj.polygon\n",
    "                hull = cv2.convexHull(np.array([point for point in points], dtype=np.float32))\n",
    "                cv2.polylines(frame, [np.int32(hull)], True, (0, 255, 0), 3)\n",
    "                \n",
    "                # Transition to face verification\n",
    "                # Show success message and wait 3 seconds\n",
    "                self.status_label.configure(text=\"✅ QR Code Detected! Preparing verification...\")\n",
    "                self.info_label.configure(text=f\"Student: {name} - Loading model...\")\n",
    "\n",
    "                # Schedule the preparation after 3 seconds\n",
    "                self.after(5000, self.prepare_face_verification)\n",
    "                return # Exit scan loop for this frame\n",
    "\n",
    "    def prepare_face_verification(self):\n",
    "        # Check if student data is still valid (prevent execution after reset)\n",
    "        if not self.current_student_id or not self.current_student_name:\n",
    "            logger.warning(\"prepare_face_verification called with invalid student data - skipping\")\n",
    "            return\n",
    "            \n",
    "        self.status_label.configure(text=\"⚙️ Preparing face verification...\", text_color=\"yellow\")\n",
    "        self.info_label.configure(text=f\"Student: {self.current_student_name} ({self.current_student_program})\")\n",
    "        \n",
    "        # Load pre-trained model for this student (instead of training PCA from scratch)\n",
    "        if not self.system.load_student_models(self.current_student_id):\n",
    "            messagebox.showerror(\"Error\", f\"No pre-trained model found for {self.current_student_name}.\")\n",
    "            self.stop_verification_process()\n",
    "            return\n",
    "        \n",
    "        # Model is loaded, ready for verification\n",
    "        self.reference_data = [{'processed': True}]  # Placeholder to indicate model is ready\n",
    "        self.verification_step = \"face_verify\"\n",
    "\n",
    "    def handle_face_verify(self, frame):\n",
    "        threshold_percent = self.system.config.MATCH_THRESHOLD * 100\n",
    "        self.status_label.configure(text=f\"📸 Step 2: Position Your Face Clearly (Threshold: {threshold_percent:.0f}%)\")\n",
    "        self.frame_count += 1\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        detected_faces = []\n",
    "        \n",
    "        if self.frame_count % 2 == 0:\n",
    "            # Use template matching from scan-template-v4.py approach\n",
    "            detected_faces = self.system.template_match_all_models(gray, self.current_student_id)\n",
    "            \n",
    "            if detected_faces:\n",
    "                # Use the best detection\n",
    "                best_detection = detected_faces[0]\n",
    "                self.last_known_face = (\n",
    "                    best_detection['x'], \n",
    "                    best_detection['y'], \n",
    "                    best_detection['width'], \n",
    "                    best_detection['height']\n",
    "                )\n",
    "            else:\n",
    "                self.last_known_face = None\n",
    "    \n",
    "        if self.last_known_face is not None:\n",
    "            x, y, w, h = self.last_known_face\n",
    "            \n",
    "            face_img = gray[y:y+h, x:x+w]\n",
    "            processed_face = self.system.preprocess_face(face_img)\n",
    "            \n",
    "            # Use the recognition method from scan-template-v4.py\n",
    "            person_id, recognized_name, pca_confidence = self.system.recognize_face_all_models(\n",
    "                face_img, self.current_student_id\n",
    "            )\n",
    "            \n",
    "            # Get template matching confidence (if available from detected_faces)\n",
    "            tm_confidence = 0.0\n",
    "            if hasattr(self, '_last_tm_confidence'):\n",
    "                tm_confidence = self._last_tm_confidence\n",
    "            \n",
    "            # Store TM confidence for next frame\n",
    "            if detected_faces:\n",
    "                self._last_tm_confidence = detected_faces[0]['confidence']\n",
    "            \n",
    "            # Combine scores (similar to scan-template-v4.py logic)\n",
    "            if recognized_name == self.current_student_name or pca_confidence > 0.7:\n",
    "                final_score = pca_confidence\n",
    "            else:\n",
    "                # Use weighted combination\n",
    "                tm_weight = 0.4\n",
    "                pca_weight = 0.6\n",
    "                final_score = (tm_confidence * tm_weight) + (pca_confidence * pca_weight)\n",
    "            \n",
    "            # Verification result logging (similar to scan-template-v4.py)\n",
    "            verification_result = {\n",
    "                'frame_number': self.frame_count,\n",
    "                'student_id': self.current_student_id,\n",
    "                'student_name': self.current_student_name,\n",
    "                'template_confidence': tm_confidence,\n",
    "                'pca_confidence': pca_confidence,\n",
    "                'final_confidence': final_score,\n",
    "                'recognized_name': recognized_name,\n",
    "                'match_threshold': self.system.config.MATCH_THRESHOLD\n",
    "            }\n",
    "            \n",
    "            logger.info(f\"Verification Result: {verification_result}\")\n",
    "            print(f\"TM: {tm_confidence:.3f}, PCA: {pca_confidence:.3f}, Final: {final_score:.3f}, Recognized: {recognized_name}\")\n",
    "            \n",
    "            self.best_score = max(self.best_score, final_score)\n",
    "            self.progress_bar.set(final_score)\n",
    "\n",
    "            if final_score > self.system.config.MATCH_THRESHOLD:\n",
    "                self.consecutive_matches += 1\n",
    "                status_text = f\"MATCHING... {self.consecutive_matches}/{self.system.config.REQUIRED_CONSECUTIVE}\"\n",
    "                status_color = \"#32CD32\"\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "            else:\n",
    "                self.consecutive_matches = 0\n",
    "                status_text = \"NO MATCH\"\n",
    "                status_color = \"red\"\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "    \n",
    "            score_text = f\"{final_score*100:.1f}%\"\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            font_scale = 0.7\n",
    "            thickness = 2\n",
    "            text_x = x\n",
    "            text_y = max(y - 10, 0)\n",
    "            cv2.putText(frame, score_text, (text_x, text_y), font, font_scale, \n",
    "                       (0, 255, 0) if final_score > self.system.config.MATCH_THRESHOLD else (0,0,255), thickness)\n",
    "\n",
    "            self.info_label.configure(\n",
    "                text=f\"Score: {final_score*100:.1f}% | Best: {self.best_score*100:.1f}% | Status: {status_text}\",\n",
    "                text_color=status_color\n",
    "            )\n",
    "    \n",
    "            if self.consecutive_matches >= self.system.config.REQUIRED_CONSECUTIVE:\n",
    "                self.finalize_verification(True)\n",
    "        else:\n",
    "            self.info_label.configure(text=\"No face detected. Please ensure good lighting.\", text_color=\"orange\")\n",
    "            self.progress_bar.set(0)\n",
    "\n",
    "    def finalize_verification(self, success):\n",
    "\n",
    "        end_time = time.time()\n",
    "        runtime = end_time - self.verification_start_time if self.verification_start_time else 0.0\n",
    "\n",
    "        # NEW: Capture the final score BEFORE resetting the state.\n",
    "        final_score = self.best_score \n",
    "        \n",
    "        timestamp = datetime.now().isoformat()\n",
    "        student_id = self.current_student_id\n",
    "        student_name = self.current_student_name\n",
    "        student_program = self.current_student_program\n",
    "        self.system.log_verification(\n",
    "            student_id, student_name,\n",
    "            student_program, success, timestamp,    \n",
    "            score=final_score  # MODIFIED: Use the captured score for logging.\n",
    "        )\n",
    "        \n",
    "        # Now, it's safe to stop and reset the process.\n",
    "        self.stop_verification_process()\n",
    "        \n",
    "        if success:\n",
    "            \n",
    "            self.status_label.configure(text=\"✅ ACCESS GRANTED\", text_color=\"green\")\n",
    "            # MODIFIED: Use the captured score for the final message.\n",
    "            self.info_label.configure(text=f\"Welcome, {student_name}! Final Score: {final_score*100:.1f}%\", text_color=\"green\")\n",
    "            self.show_student_details_screen(student_id, final_score)\n",
    "        else:\n",
    "            self.status_label.configure(text=\"❌ ACCESS DENIED\", text_color=\"red\")\n",
    "            self.info_label.configure(text=f\"Face not recognized. Best score: {final_score*100:.1f}%\", text_color=\"red\")\n",
    "            messagebox.showerror(\"Failure\", \"Face verification failed.\")\n",
    "            \n",
    "        try:\n",
    "            result_logger.save_result(\n",
    "                member_name=self.member_name,\n",
    "                student_id=student_id,\n",
    "                score=final_score,\n",
    "                runtime=runtime\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to log result: {e}\")\n",
    "            \n",
    "        # Reset labels to default after a delay\n",
    "        self.after(5000, self.reset_labels)\n",
    "    \n",
    "    def reset_labels(self):\n",
    "        self.status_label.configure(text=\"Welcome! Click 'Start Verification' to begin.\", text_color=(\"white\", \"black\"))\n",
    "        self.progress_bar.set(0)\n",
    "        self.info_label.configure(text=\"\")\n",
    "        \n",
    "\n",
    "    def on_closing(self):\n",
    "        # Stop verification if still active\n",
    "        if self.verification_active:\n",
    "            self.stop_verification_process()\n",
    "    \n",
    "        # Release camera if still open\n",
    "        if self.cap and self.cap.isOpened():\n",
    "            self.cap.release()\n",
    "            self.cap = None\n",
    "    \n",
    "        # Stop TTS engine safely\n",
    "        try:\n",
    "            if hasattr(self, 'tts_system'):\n",
    "                self.tts_system.cleanup()\n",
    "        except Exception as e:\n",
    "            print(f\"TTS cleanup failed: {e}\")\n",
    "    \n",
    "        # Close Tkinter\n",
    "        self.quit()     # stop mainloop\n",
    "        self.destroy()  # destroy window\n",
    "    \n",
    "        sys.exit(0)     # graceful exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "84764285",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-27 23:08:08,315 - INFO - Loaded data for 6 students\n",
      "2025-08-27 23:08:08,316 - INFO - Student Verification System backend initialized\n",
      "2025-08-27 23:08:08,482 - INFO - RobustTTS worker thread started.\n",
      "2025-08-27 23:08:41,242 - INFO - QR ID 'S005' found in database for student: Jose\n",
      "2025-08-27 23:08:41,721 - INFO - QR ID 'S005' found in database for student: Jose\n",
      "2025-08-27 23:08:41,778 - INFO - QR ID 'S005' found in database for student: Jose\n",
      "2025-08-27 23:08:41,837 - INFO - QR ID 'S005' found in database for student: Jose\n",
      "2025-08-27 23:08:41,900 - INFO - QR ID 'S005' found in database for student: Jose\n",
      "2025-08-27 23:08:42,073 - INFO - QR ID 'S005' found in database for student: Jose\n",
      "2025-08-27 23:08:42,137 - INFO - QR ID 'S005' found in database for student: Jose\n",
      "2025-08-27 23:08:42,198 - INFO - QR ID 'S005' found in database for student: Jose\n",
      "2025-08-27 23:08:46,268 - INFO - Loaded model for S005: 30 faces, 5 templates\n",
      "2025-08-27 23:08:46,734 - INFO - Loaded model for S005: 30 faces, 5 templates\n",
      "2025-08-27 23:08:46,787 - INFO - Loaded model for S005: 30 faces, 5 templates\n",
      "2025-08-27 23:08:46,967 - INFO - Loaded model for S005: 30 faces, 5 templates\n",
      "2025-08-27 23:08:46,988 - INFO - Loaded model for S005: 30 faces, 5 templates\n",
      "2025-08-27 23:08:47,222 - INFO - Loaded model for S005: 30 faces, 5 templates\n",
      "2025-08-27 23:08:47,227 - INFO - Loaded model for S005: 30 faces, 5 templates\n",
      "2025-08-27 23:08:47,234 - INFO - Loaded model for S005: 30 faces, 5 templates\n",
      "2025-08-27 23:09:41,625 - INFO - Recognition result: ID=-1, Name=unknown, Confidence=0.617\n",
      "2025-08-27 23:09:41,626 - INFO - Verification Result: {'frame_number': 500, 'student_id': 'S005', 'student_name': 'Jose', 'template_confidence': 0.0, 'pca_confidence': np.float64(0.6170497086964625), 'final_confidence': np.float64(0.37022982521787745), 'recognized_name': 'unknown', 'match_threshold': 0.7}\n",
      "2025-08-27 23:09:41,685 - INFO - Recognition result: ID=-1, Name=unknown, Confidence=0.492\n",
      "2025-08-27 23:09:41,685 - INFO - Verification Result: {'frame_number': 501, 'student_id': 'S005', 'student_name': 'Jose', 'template_confidence': 0.6013944745063782, 'pca_confidence': np.float64(0.49167946659129735), 'final_confidence': np.float64(0.5355654697573297), 'recognized_name': 'unknown', 'match_threshold': 0.7}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TM: 0.000, PCA: 0.617, Final: 0.370, Recognized: unknown\n",
      "TM: 0.601, PCA: 0.492, Final: 0.536, Recognized: unknown\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-27 23:09:41,862 - INFO - Recognition result: ID=-1, Name=unknown, Confidence=0.739\n",
      "2025-08-27 23:09:41,863 - INFO - Verification Result: {'frame_number': 502, 'student_id': 'S005', 'student_name': 'Jose', 'template_confidence': 0.6013944745063782, 'pca_confidence': np.float64(0.738588229743411), 'final_confidence': np.float64(0.738588229743411), 'recognized_name': 'unknown', 'match_threshold': 0.7}\n",
      "2025-08-27 23:09:41,917 - INFO - Recognition result: ID=-1, Name=unknown, Confidence=0.533\n",
      "2025-08-27 23:09:41,917 - INFO - Verification Result: {'frame_number': 503, 'student_id': 'S005', 'student_name': 'Jose', 'template_confidence': 0.6547853350639343, 'pca_confidence': np.float64(0.5332354835655553), 'final_confidence': np.float64(0.5818554241649069), 'recognized_name': 'unknown', 'match_threshold': 0.7}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TM: 0.601, PCA: 0.739, Final: 0.739, Recognized: unknown\n",
      "TM: 0.655, PCA: 0.533, Final: 0.582, Recognized: unknown\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-27 23:09:42,086 - INFO - Recognition result: ID=-1, Name=unknown, Confidence=0.737\n",
      "2025-08-27 23:09:42,088 - INFO - Verification Result: {'frame_number': 504, 'student_id': 'S005', 'student_name': 'Jose', 'template_confidence': 0.6547853350639343, 'pca_confidence': np.float64(0.7369745734374472), 'final_confidence': np.float64(0.7369745734374472), 'recognized_name': 'unknown', 'match_threshold': 0.7}\n",
      "2025-08-27 23:09:42,135 - INFO - Recognition result: ID=-1, Name=unknown, Confidence=0.672\n",
      "2025-08-27 23:09:42,136 - INFO - Verification Result: {'frame_number': 505, 'student_id': 'S005', 'student_name': 'Jose', 'template_confidence': 0.6688612699508667, 'pca_confidence': np.float64(0.671606093714339), 'final_confidence': np.float64(0.6705081642089501), 'recognized_name': 'unknown', 'match_threshold': 0.7}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TM: 0.655, PCA: 0.737, Final: 0.737, Recognized: unknown\n",
      "TM: 0.669, PCA: 0.672, Final: 0.671, Recognized: unknown\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-27 23:09:42,309 - INFO - Recognition result: ID=-1, Name=unknown, Confidence=0.785\n",
      "2025-08-27 23:09:42,310 - INFO - Verification Result: {'frame_number': 506, 'student_id': 'S005', 'student_name': 'Jose', 'template_confidence': 0.6688612699508667, 'pca_confidence': np.float64(0.7850530226207085), 'final_confidence': np.float64(0.7850530226207085), 'recognized_name': 'unknown', 'match_threshold': 0.7}\n",
      "2025-08-27 23:09:42,357 - INFO - Recognition result: ID=-1, Name=unknown, Confidence=0.770\n",
      "2025-08-27 23:09:42,358 - INFO - Verification Result: {'frame_number': 507, 'student_id': 'S005', 'student_name': 'Jose', 'template_confidence': 0.629371166229248, 'pca_confidence': np.float64(0.7697360850831564), 'final_confidence': np.float64(0.7697360850831564), 'recognized_name': 'unknown', 'match_threshold': 0.7}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TM: 0.669, PCA: 0.785, Final: 0.785, Recognized: unknown\n",
      "TM: 0.629, PCA: 0.770, Final: 0.770, Recognized: unknown\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-27 23:09:42,527 - INFO - Recognition result: ID=-1, Name=unknown, Confidence=0.780\n",
      "2025-08-27 23:09:42,528 - INFO - Verification Result: {'frame_number': 508, 'student_id': 'S005', 'student_name': 'Jose', 'template_confidence': 0.629371166229248, 'pca_confidence': np.float64(0.7800705481186946), 'final_confidence': np.float64(0.7800705481186946), 'recognized_name': 'unknown', 'match_threshold': 0.7}\n",
      "2025-08-27 23:09:42,542 - INFO - Verification logged: Jose - SUCCESS (Score: 0.785)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TM: 0.629, PCA: 0.780, Final: 0.780, Recognized: unknown\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-27 23:09:43,045 - INFO - Loaded student photo: card_photos\\S005.jpg\n",
      "2025-08-27 23:09:43,087 - INFO - Voice announcement: Verification successful. Welcome, Jose. Program: CS. Batch 2022. Academic performance: Pass. Access granted. Have a great day!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Result saved for Member1: Score=0.785, Runtime=67.279s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-27 23:10:16,325 - INFO - QR ID 'S006' found in database for student: chan\n",
      "2025-08-27 23:10:16,384 - INFO - QR ID 'S006' found in database for student: chan\n",
      "2025-08-27 23:10:16,451 - INFO - QR ID 'S006' found in database for student: chan\n",
      "2025-08-27 23:10:16,517 - INFO - QR ID 'S006' found in database for student: chan\n",
      "2025-08-27 23:10:16,593 - INFO - QR ID 'S006' found in database for student: chan\n",
      "2025-08-27 23:10:16,765 - INFO - QR ID 'S006' found in database for student: chan\n",
      "2025-08-27 23:10:21,348 - INFO - Loaded model for S006: 30 faces, 5 templates\n",
      "2025-08-27 23:10:21,395 - INFO - Loaded model for S006: 30 faces, 5 templates\n",
      "2025-08-27 23:10:21,535 - INFO - Recognition result: ID=-1, Name=unknown, Confidence=0.692\n",
      "2025-08-27 23:10:21,536 - INFO - Verification Result: {'frame_number': 2, 'student_id': 'S006', 'student_name': 'chan', 'template_confidence': 0.6142845749855042, 'pca_confidence': np.float64(0.6918418353550345), 'final_confidence': np.float64(0.6608189312072223), 'recognized_name': 'unknown', 'match_threshold': 0.7}\n",
      "2025-08-27 23:10:21,566 - INFO - Loaded model for S006: 30 faces, 5 templates\n",
      "2025-08-27 23:10:21,571 - INFO - Loaded model for S006: 30 faces, 5 templates\n",
      "2025-08-27 23:10:21,584 - INFO - Recognition result: ID=-1, Name=unknown, Confidence=0.705\n",
      "2025-08-27 23:10:21,585 - INFO - Verification Result: {'frame_number': 3, 'student_id': 'S006', 'student_name': 'chan', 'template_confidence': 0.7537374496459961, 'pca_confidence': np.float64(0.7048701684900295), 'final_confidence': np.float64(0.7048701684900295), 'recognized_name': 'unknown', 'match_threshold': 0.7}\n",
      "2025-08-27 23:10:21,613 - INFO - Loaded model for S006: 30 faces, 5 templates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TM: 0.614, PCA: 0.692, Final: 0.661, Recognized: unknown\n",
      "TM: 0.754, PCA: 0.705, Final: 0.705, Recognized: unknown\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-27 23:10:21,749 - INFO - Recognition result: ID=-1, Name=unknown, Confidence=0.667\n",
      "2025-08-27 23:10:21,750 - INFO - Verification Result: {'frame_number': 4, 'student_id': 'S006', 'student_name': 'chan', 'template_confidence': 0.7537374496459961, 'pca_confidence': np.float64(0.6669826325562705), 'final_confidence': np.float64(0.7016845593921608), 'recognized_name': 'unknown', 'match_threshold': 0.7}\n",
      "2025-08-27 23:10:21,781 - INFO - Loaded model for S006: 30 faces, 5 templates\n",
      "2025-08-27 23:10:21,810 - INFO - Recognition result: ID=-1, Name=unknown, Confidence=0.708\n",
      "2025-08-27 23:10:21,811 - INFO - Verification Result: {'frame_number': 5, 'student_id': 'S006', 'student_name': 'chan', 'template_confidence': 0.7510167956352234, 'pca_confidence': np.float64(0.7080040088948315), 'final_confidence': np.float64(0.7080040088948315), 'recognized_name': 'unknown', 'match_threshold': 0.7}\n",
      "2025-08-27 23:10:21,824 - INFO - Verification logged: chan - SUCCESS (Score: 0.708)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TM: 0.754, PCA: 0.667, Final: 0.702, Recognized: unknown\n",
      "TM: 0.751, PCA: 0.708, Final: 0.708, Recognized: unknown\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-27 23:10:22,359 - INFO - Loaded student photo: card_photos\\S006.jpg\n",
      "2025-08-27 23:10:22,400 - INFO - Voice announcement: Verification successful. Welcome, chan. Program: sd. Batch 2033. Academic performance: Second Class Lower. Access granted. Have a great day!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Result saved for Member1: Score=0.708, Runtime=9.116s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-27 23:11:50,201 - INFO - Cleaning up TTS system...\n",
      "2025-08-27 23:11:50,202 - INFO - TTS system cleaned up.\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LYL\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        config = Config()\n",
    "        backend_system = StudentSystem(config)\n",
    "        app = App(student_system=backend_system)\n",
    "        app.mainloop()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n👋 System interrupted by user. Goodbye!\")\n",
    "    except Exception as e:\n",
    "        logger.critical(f\"Critical system error on startup: {e}\")\n",
    "        print(f\"💥 Critical error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddbf292",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
